{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c51ae16-3813-45b7-a36c-9f02e1779468",
   "metadata": {},
   "source": [
    "# ElecForecast - Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc94e618-24e6-46ea-af78-7863d079ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -Uqq fastai\n",
    "# !pip install -Uqq xgboost\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import io\n",
    "import shutil\n",
    "import zipfile \n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from datetime import datetime, timedelta, date\n",
    "import timeit\n",
    "np.random.seed(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import logistic\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "import joblib\n",
    "import xgboost\n",
    "# from fastai.tabular.all import *\n",
    "import fastai.tabular.all as fastai\n",
    "\n",
    "from aemo import *\n",
    "    \n",
    "# Display floats in this notbook to 3 decimal places\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "plt.rcParams[\"figure.figsize\"] = (16,10)\n",
    "\n",
    "# Constants\n",
    "MODELS_FOLDER = Path('../models')\n",
    "REGIONIDS = ['NSW1', 'QLD1', 'SA1', 'TAS1', 'VIC1']\n",
    "FORECAST_TIMES = list(range(2,24,2)) + list(range(24,168+1,4))  # every 2hrs for 24hrs, then every 4hrs to 168 (week)\n",
    "ENSEMBLE_RATIO = 0.6  # nn * ENSEMBLE_RATIO  +  xgb (1-ENSEMBLE_RATIO) == prediction\n",
    "p_min, p_max = -400, 1000 # values to clip price columns to when decoding\n",
    "# list of forecasts to make, eg 'VIC1_Price' where forecast is a list of predictions at FORECAST_TIMES (ie up to a week out)\n",
    "FORECASTS_TO_MAKE = [f\"{region}_{price_or_greenness}\" for region in REGIONIDS for price_or_greenness in ['Price', 'Greenness']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3766742d-b196-40c0-9990-0b2f65ac6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded ../data/download_cache/duids_from_neo.json\n"
     ]
    }
   ],
   "source": [
    "duids = get_duids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21fc4c-6f73-4826-9be7-3a250c93b135",
   "metadata": {},
   "source": [
    "### NEM Data Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179b236-8b51-4c71-aee5-4ddf3100d1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Global Constants\n",
    "REGIONIDS = ['NSW1', 'QLD1', 'SA1', 'TAS1', 'VIC1']\n",
    "INTERCONNECTORIDS = ['N-Q-MNSP1', 'NSW1-QLD1', 'T-V-MNSP1', 'V-S-MNSP1', 'V-SA', 'VIC1-NSW1']\n",
    "MAX_CSV_FILE_SIZE_TO_KEEP_ON_DISK_IN_BYTES = 10000000 \n",
    "DATA_FOLDER = Path('../data')\n",
    "DOWNLOAD_CACHE_FOLDER = DATA_FOLDER / 'download_cache'\n",
    "\n",
    "\n",
    "def ppjson(x):\n",
    "    if isinstance(x, str):\n",
    "        print(json.dumps(json.loads(x), indent=2))\n",
    "    if isinstance(x, dict) or isinstance(x, list):\n",
    "        print(json.dumps(x, indent=2))\n",
    "\n",
    "# often need to turn 5-minute data into 1-hour data. \n",
    "# All timestamps in dataset are at the END of a period, so can't just .replace(minute=0).\n",
    "# We want to round UP to next hour. \n",
    "# round_up_to_hour = lambda x: (x+timedelta(minutes=55)).replace(minute=0)\n",
    "def round_up_to_hour(df, column):\n",
    "    df[column] = df[column].apply(lambda x: (x+timedelta(minutes=55)).replace(minute=0))\n",
    "    return df\n",
    "\n",
    "# print ALL columns from just two rows, displays all even when pandas cuts everything off.\n",
    "def print_item(df, index=0, offset=1):\n",
    "    cells = list(zip([x for x in df.columns],[x for x in df.iloc[index]],[x for x in df.iloc[index+offset]]))\n",
    "    [print(f'{a[0]:30}{a[1]:<30}{a[2]:<30}') for a in cells]\n",
    "\n",
    "def check_nas(df):\n",
    "    return df.loc[df.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1cccff-7bdf-465d-9df3-08e0fb9de32a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927143d-7564-4590-8eaa-ab02d65de38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc598561-bf80-4ad2-b9bb-9b9091a4ef6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../data/columns_for_VIC1.json') as f:\n",
    "    dataset_cols = json.loads(f.read())\n",
    "# dataset_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e92f0c-24b7-4525-8d59-0bf5f3ef1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dataset_cols) - set(features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9dc3d1-b4ca-4e91-bb16-4627d87e610c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    # Day features - calculatd\n",
    "    'day', 'hour', 'hours_since_2010', 'is_weekend', 'month', 'quarter', 'weekday', 'year', \n",
    "\n",
    "    # Holidays - from scraped holidays data\n",
    "    'RG_is_holiday', \n",
    "    'RG_is_workday',   'RG_is_workday_Tp24', 'RG_is_workday_Tp48', 'RG_is_workday_Tp72', 'RG_is_workday_Tp96', 'RG_is_workday_Tp120', 'RG_is_workday_Tp144', 'RG_is_workday_Tp168', \n",
    "\n",
    "# Weather\n",
    "    'RG_W_temperature', \n",
    "    'RG_W_day_max_temperature', 'RG_W_day_max_temperature_Tp24', 'RG_W_day_max_temperature_Tp48', 'RG_W_day_max_temperature_Tp72', 'RG_W_day_max_temperature_Tp96', 'RG_W_day_max_temperature_Tp120', 'RG_W_day_max_temperature_Tp144', 'RG_W_day_max_temperature_Tp168', \n",
    "# 'RG_W_sun', 'RG_W_cloud', 'RG_W_wind', \n",
    "# 'RG_W_day_max_sun',         'RG_W_day_max_sun_Tp24', 'RG_W_day_max_sun_Tp48', 'RG_W_day_max_sun_Tp72', 'RG_W_day_max_sun_Tp96', 'RG_W_day_max_sun_Tp120', 'RG_W_day_max_sun_Tp144', 'RG_W_day_max_sun_Tp168', \n",
    "# 'RG_W_day_max_wind',        'RG_W_day_max_wind_Tp24','RG_W_day_max_wind_Tp48', 'RG_W_day_max_wind_Tp72', 'RG_W_day_max_wind_Tp96', 'RG_W_day_max_wind_Tp120', 'RG_W_day_max_wind_Tp144', 'RG_W_day_max_wind_Tp168', \n",
    "\n",
    "    # Price & generation by region - From various sub-tables in \"DISPATCHIS\" \n",
    "    'RG_Price', \n",
    "    'RG_GENERATION', 'RG_AVAILABLEGENERATION', 'RG_TOTALDEMAND',\n",
    "    'RG_IC_NET', 'RG_IC_Export_Limit', 'RG_IC_Import_Limit', \n",
    "    \n",
    "    # Price lags - using table \"TradingIS_Reports\"\n",
    "    'RG_Price_Tm1', 'RG_Price_Tm2', 'RG_Price_Tm3', 'RG_Price_Tm4', 'RG_Price_Tm6', 'RG_Price_Tm8', 'RG_Price_Tm12', 'RG_Price_Tm16', 'RG_Price_Tm20', 'RG_Price_Tm24', \n",
    "    'RG_Price_Tm36', 'RG_Price_Tm48', 'RG_Price_Tm168', \n",
    "    'RG_Price_Tm30d_25thP', 'RG_Price_Tm30d_Median', 'RG_Price_Tm30d_75thP', 'RG_Price_Tm30d_Mean', \n",
    "\n",
    "    # Forecasts of Region stats:\n",
    "    # PREDISPATCHIS table > REGION_SOLUTION subtable until 4.30 day-after-next trading day, jioned with STPASA table, REGIONSOLUTION sub-table for the remainder of 7 days ahead\n",
    "    'RG_AVAILABLEGENERATION_Tp6', 'RG_AVAILABLEGENERATION_Tp12', 'RG_AVAILABLEGENERATION_Tp18', 'RG_AVAILABLEGENERATION_Tp24', 'RG_AVAILABLEGENERATION_Tp30', 'RG_AVAILABLEGENERATION_Tp36', 'RG_AVAILABLEGENERATION_Tp42', 'RG_AVAILABLEGENERATION_Tp48', 'RG_AVAILABLEGENERATION_Tp54', 'RG_AVAILABLEGENERATION_Tp60', 'RG_AVAILABLEGENERATION_Tp66', 'RG_AVAILABLEGENERATION_Tp72', 'RG_AVAILABLEGENERATION_Tp78', 'RG_AVAILABLEGENERATION_Tp84', 'RG_AVAILABLEGENERATION_Tp90', 'RG_AVAILABLEGENERATION_Tp96', 'RG_AVAILABLEGENERATION_Tp102', 'RG_AVAILABLEGENERATION_Tp108', 'RG_AVAILABLEGENERATION_Tp114', 'RG_AVAILABLEGENERATION_Tp120', 'RG_AVAILABLEGENERATION_Tp126', 'RG_AVAILABLEGENERATION_Tp132', 'RG_AVAILABLEGENERATION_Tp138', 'RG_AVAILABLEGENERATION_Tp144', 'RG_AVAILABLEGENERATION_Tp150', 'RG_AVAILABLEGENERATION_Tp156', 'RG_AVAILABLEGENERATION_Tp162', 'RG_AVAILABLEGENERATION_Tp168', \n",
    "    'RG_TOTALDEMAND_Tp6', 'RG_TOTALDEMAND_Tp12', 'RG_TOTALDEMAND_Tp18', 'RG_TOTALDEMAND_Tp24', 'RG_TOTALDEMAND_Tp30', 'RG_TOTALDEMAND_Tp36', 'RG_TOTALDEMAND_Tp42', 'RG_TOTALDEMAND_Tp48', 'RG_TOTALDEMAND_Tp54', 'RG_TOTALDEMAND_Tp60', 'RG_TOTALDEMAND_Tp66', 'RG_TOTALDEMAND_Tp72', 'RG_TOTALDEMAND_Tp78', 'RG_TOTALDEMAND_Tp84', 'RG_TOTALDEMAND_Tp90', 'RG_TOTALDEMAND_Tp96', 'RG_TOTALDEMAND_Tp102', 'RG_TOTALDEMAND_Tp108', 'RG_TOTALDEMAND_Tp114', 'RG_TOTALDEMAND_Tp120', 'RG_TOTALDEMAND_Tp126', 'RG_TOTALDEMAND_Tp132', 'RG_TOTALDEMAND_Tp138', 'RG_TOTALDEMAND_Tp144', 'RG_TOTALDEMAND_Tp150', 'RG_TOTALDEMAND_Tp156', 'RG_TOTALDEMAND_Tp162', 'RG_TOTALDEMAND_Tp168', \n",
    "    'RG_GEN_Solar_Tp6', 'RG_GEN_Solar_Tp12', 'RG_GEN_Solar_Tp18', 'RG_GEN_Solar_Tp24', 'RG_GEN_Solar_Tp30', 'RG_GEN_Solar_Tp36', 'RG_GEN_Solar_Tp42', 'RG_GEN_Solar_Tp48', 'RG_GEN_Solar_Tp54', 'RG_GEN_Solar_Tp60', 'RG_GEN_Solar_Tp66', 'RG_GEN_Solar_Tp72', 'RG_GEN_Solar_Tp78', 'RG_GEN_Solar_Tp84', 'RG_GEN_Solar_Tp90', 'RG_GEN_Solar_Tp96', 'RG_GEN_Solar_Tp102', 'RG_GEN_Solar_Tp108', 'RG_GEN_Solar_Tp114', 'RG_GEN_Solar_Tp120', 'RG_GEN_Solar_Tp126', 'RG_GEN_Solar_Tp132', 'RG_GEN_Solar_Tp138', 'RG_GEN_Solar_Tp144', 'RG_GEN_Solar_Tp150', 'RG_GEN_Solar_Tp156', 'RG_GEN_Solar_Tp162', 'RG_GEN_Solar_Tp168', \n",
    "    'RG_GEN_Wind_Tp6', 'RG_GEN_Wind_Tp12', 'RG_GEN_Wind_Tp18', 'RG_GEN_Wind_Tp24', 'RG_GEN_Wind_Tp30', 'RG_GEN_Wind_Tp36', 'RG_GEN_Wind_Tp42', 'RG_GEN_Wind_Tp48', 'RG_GEN_Wind_Tp54', 'RG_GEN_Wind_Tp60', 'RG_GEN_Wind_Tp66', 'RG_GEN_Wind_Tp72', 'RG_GEN_Wind_Tp78', 'RG_GEN_Wind_Tp84', 'RG_GEN_Wind_Tp90', 'RG_GEN_Wind_Tp96', 'RG_GEN_Wind_Tp102', 'RG_GEN_Wind_Tp108', 'RG_GEN_Wind_Tp114', 'RG_GEN_Wind_Tp120', 'RG_GEN_Wind_Tp126', 'RG_GEN_Wind_Tp132', 'RG_GEN_Wind_Tp138', 'RG_GEN_Wind_Tp144', 'RG_GEN_Wind_Tp150', 'RG_GEN_Wind_Tp156', 'RG_GEN_Wind_Tp162', 'RG_GEN_Wind_Tp168', \n",
    "\n",
    "    # Availability by fuel type - use 24h ago (because now isn't available). \n",
    "    'RG_AVAILABILITY_Battery Storage', 'RG_AVAILABILITY_Coal', 'RG_AVAILABILITY_Gas', 'RG_AVAILABILITY_Hydro', 'RG_AVAILABILITY_Solar', 'RG_AVAILABILITY_Wind', \n",
    "\n",
    "    # From 'DISPATCHSCADA': generation by fuel type\n",
    "    'RG_GEN_Battery Storage', 'RG_GEN_Coal', 'RG_GEN_Gas', 'RG_GEN_Hydro', 'RG_GEN_Solar', 'RG_GEN_Wind', \n",
    "\n",
    "    # ROOFTOP_PV_ACTUAL / ROOFTOP_PV_FORECAST\n",
    "    'RG_GEN_Rooftop', \n",
    "    'RG_GEN_Rooftop_Tp6', 'RG_GEN_Rooftop_Tp12', 'RG_GEN_Rooftop_Tp18', 'RG_GEN_Rooftop_Tp24', 'RG_GEN_Rooftop_Tp30', 'RG_GEN_Rooftop_Tp36', 'RG_GEN_Rooftop_Tp42', 'RG_GEN_Rooftop_Tp48', 'RG_GEN_Rooftop_Tp54', 'RG_GEN_Rooftop_Tp60', 'RG_GEN_Rooftop_Tp66', 'RG_GEN_Rooftop_Tp72', 'RG_GEN_Rooftop_Tp78', 'RG_GEN_Rooftop_Tp84', 'RG_GEN_Rooftop_Tp90', 'RG_GEN_Rooftop_Tp96', 'RG_GEN_Rooftop_Tp102', 'RG_GEN_Rooftop_Tp108', 'RG_GEN_Rooftop_Tp114', 'RG_GEN_Rooftop_Tp120', 'RG_GEN_Rooftop_Tp126', 'RG_GEN_Rooftop_Tp132', 'RG_GEN_Rooftop_Tp138', 'RG_GEN_Rooftop_Tp144', 'RG_GEN_Rooftop_Tp150', 'RG_GEN_Rooftop_Tp156', 'RG_GEN_Rooftop_Tp162', 'RG_GEN_Rooftop_Tp168', \n",
    "\n",
    "    # TODO: ... but IC_NET is hard... not sure I can trust that data. Maybe change the model, should have used import/export limits not IC_NET. \n",
    "# 'RG_IC_NET_Tp6', 'RG_IC_NET_Tp12', 'RG_IC_NET_Tp18', 'RG_IC_NET_Tp24', 'RG_IC_NET_Tp30', 'RG_IC_NET_Tp36', 'RG_IC_NET_Tp42', 'RG_IC_NET_Tp48', 'RG_IC_NET_Tp54', 'RG_IC_NET_Tp60', 'RG_IC_NET_Tp66', 'RG_IC_NET_Tp72', 'RG_IC_NET_Tp78', 'RG_IC_NET_Tp84', 'RG_IC_NET_Tp90', 'RG_IC_NET_Tp96', 'RG_IC_NET_Tp102', 'RG_IC_NET_Tp108', 'RG_IC_NET_Tp114', 'RG_IC_NET_Tp120', 'RG_IC_NET_Tp126', 'RG_IC_NET_Tp132', 'RG_IC_NET_Tp138', 'RG_IC_NET_Tp144', 'RG_IC_NET_Tp150', 'RG_IC_NET_Tp156', 'RG_IC_NET_Tp162', 'RG_IC_NET_Tp168'\n",
    "    \n",
    "    # Calculated:\n",
    "    'RG_Greenness', \n",
    "    'RG_Greenness_Tm30d_Mean', \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b33157-1078-488f-98f9-86289a0c062e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Date Features\n",
    "'day', 'hour', 'hours_since_2010', 'is_weekend', 'month', 'quarter', 'weekday', 'year',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84045d-8af5-480f-a51f-c72020fcea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_features():\n",
    "    output = {}\n",
    "    now = pd.Timestamp.now(tz='Australia/Brisbane').to_pydatetime()\n",
    "    output['year'] = now.year - 2010\n",
    "    output['month'] = now.month\n",
    "    output['day'] = now.day\n",
    "    output['hour'] = now.hour\n",
    "    output['weekday'] = now.weekday()\n",
    "    output['quarter'] = ((now.month-1) // 3)+1 + (now.year-2010) * 4\n",
    "    output['is_weekend'] = now.weekday() >= 5\n",
    "\n",
    "\n",
    "    # hours_since_2010: note, not actually hours, it's timesteps, and they are now 5 min timesteps. \n",
    "    # also it's rounded to 3 sig figs as a float... wonder if that's enough...\n",
    "    # 9 Jan 2010 happens to equal 2020\n",
    "    START_DATE = datetime(2010, 1, 2)\n",
    "\n",
    "    def datetime_to_x_since_2010(dt): \n",
    "        delta = dt.replace(tzinfo=None) - START_DATE\n",
    "        x = delta.total_seconds() / 60 / 5\n",
    "        return int(float('%.3g' % x))\n",
    "    # tests from dataset6\n",
    "    assert datetime_to_x_since_2010(datetime(2010, 1, 9)) == 2020\n",
    "    assert datetime_to_x_since_2010(datetime(2022, 6, 20, 10)) == 1310000\n",
    "    assert datetime_to_x_since_2010(datetime(2010, 1, 15, 22, 34, 0)) == 4010\n",
    "    assert datetime_to_x_since_2010(datetime(2010, 1, 15, 22, 35, 0)) == 4020\n",
    "\n",
    "    output['hours_since_2010'] = datetime_to_x_since_2010(now)\n",
    "    \n",
    "    return output\n",
    "\n",
    "features = features | output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c3f124-b522-486e-b881-44ffe4b0e991",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Holidays, workdays, workday forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f4b19-1fb8-40bd-a843-87d8bd8f8a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_workday_features()\n",
    "    \"\"\"Get features for holidays and workdays\"\"\"\n",
    "    output = {}\n",
    "    holidays = pd.read_csv(DATA_FOLDER / 'australian_public_holidays_scraped_2010-2024.csv', parse_dates=['Date'], index_col=0)\n",
    "    holidays = ~holidays.pivot(index='Date', columns='REGIONID').isna()\n",
    "    holidays.columns = [f\"{x[1]}_is_holiday\" for x in holidays.columns]\n",
    "\n",
    "    def get_is_holiday(date, region):\n",
    "        date_str = date.isoformat()\n",
    "        if date_str in holidays.index:\n",
    "            region_is_holiday = holidays.loc[date_str, f'{region}_is_holiday']\n",
    "        else:\n",
    "            region_is_holiday = False\n",
    "        return region_is_holiday\n",
    "\n",
    "    assert get_is_holiday(date(2010, 1, 26), 'SA1') == True\n",
    "    assert get_is_holiday(date(2010, 1, 30), 'QLD1') == False\n",
    "    assert get_is_holiday(date(2024, 11, 4), 'NSW1') == False\n",
    "    assert get_is_holiday(date(2024, 11, 5), 'VIC1') == True\n",
    "\n",
    "\n",
    "    # NEM time = AEST = Brisbane, because they don't have daylight savings time\n",
    "    today = pd.Timestamp.now(tz='Australia/Brisbane').normalize().to_pydatetime().date()\n",
    "\n",
    "    for region in REGIONIDS:\n",
    "        output[f'{region}_is_holiday'] = get_is_holiday(today, region)\n",
    "        output[f'{region}_is_workday'] = not (output['is_weekend'] or output[f'{region}_is_holiday'])\n",
    "\n",
    "    next_7_days = [today + timedelta(days=x) for x in range(1, 7+1)]\n",
    "\n",
    "    is_weekend_forecast = [day.weekday() >= 5 for day in next_7_days]\n",
    "\n",
    "    for region in REGIONIDS:\n",
    "        is_holiday_forecast = [get_is_holiday(day, region) for day in next_7_days]\n",
    "        is_workday_forecast = [not(weekend or holiday) for weekend, holiday in list(zip(is_weekend_forecast, is_holiday_forecast))]\n",
    "        is_workday_forecast\n",
    "\n",
    "        for i, is_workday in enumerate(is_workday_forecast):\n",
    "            output[f'{region}_is_workday_Tp{24 * (i+1)}'] = is_workday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecaa28b-d597-4011-9b4d-7888bb5fc8e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Weather Forecasts\n",
    "- 'RG_W_temperature', 'RG_W_wind', \n",
    "- 'RG_W_sun', 'RG_W_cloud', \n",
    "- 'RG_W_day_max_temperature', 'RG_W_day_max_temperature_Tp24', 'RG_W_day_max_temperature_Tp48',  'RG_W_day_max_temperature_Tp72', 'RG_W_day_max_temperature_Tp96', 'RG_W_day_max_temperature_Tp120',  'RG_W_day_max_temperature_Tp144', 'RG_W_day_max_temperature_Tp168', \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddb5e2-fd6d-4d33-8ded-51b6ded7243b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weather_features():\n",
    "    \"\"\"get max temp forecasts from the BoM\n",
    "    \n",
    "    Data comes from the api used in https://weather.bom.gov.au/location/r1r0fsn-melbourne and similar pages\n",
    "    Dodgy: sometimes is short one day. See below\n",
    "    \"\"\"\n",
    "    bom_codes = {\n",
    "        'NSW1': 'r3gx2f',\n",
    "        'VIC1': 'r1r0fs',\n",
    "        'TAS1': 'r22u09',\n",
    "        'QLD1': 'r7hgdp',\n",
    "        'SA1': 'r1f93c',\n",
    "    }\n",
    "    output = {}\n",
    "    for region in REGIONIDS:\n",
    "    # for region in ['SA1']:\n",
    "\n",
    "        # get current temperature\n",
    "        r = requests.get(f'https://api.weather.bom.gov.au/v1/locations/{bom_codes[region]}/observations')\n",
    "        observation = r.json()\n",
    "        output[f'{region}_W_temperature'] = observation['data']['temp']\n",
    "        max_temp_today = observation['data']['max_temp']['value']\n",
    "    \n",
    "        # get forecast temperatures\n",
    "        r = requests.get(f'https://api.weather.bom.gov.au/v1/locations/{bom_codes[region]}/forecasts/daily')\n",
    "        forecast = r.json()\n",
    "\n",
    "        # extract date & max_temp from the BoM data.  Round to nearest day to avoid having to deal with DST or each city's particular timezone.\n",
    "        temps_lookup = {pd.Timestamp(x['date']).tz_convert('Australia/Brisbane').round('D').tz_localize(tz=None): x['temp_max'] \n",
    "                        for x in forecast['data']}\n",
    "\n",
    "        # need to match those dates against the desired dates, which start from 'today' (regardless of current time) and then 7 more days after that.\n",
    "        today = (pd.Timestamp.utcnow()\n",
    "                 .tz_convert('Australia/Brisbane')  # Use Brisbane tz beacuse always AEST (no DST)\n",
    "                 .floor('D')\n",
    "                 .tz_localize(tz=None))  # remove timezone\n",
    "        days = [today + pd.Timedelta(x, 'D') for x in range(8)]\n",
    "        if today not in temps_lookup: temps_lookup[today] = None\n",
    "        if days[-1] not in temps_lookup: temps_lookup[days[-1]] = None\n",
    "        temps = [temps_lookup[day] for day in days]\n",
    "        # dodgy hack if there's one day short: copy from previous day\n",
    "        # dataset7 has current day's max temp (depending on current time, this could be future or \n",
    "        # past) and requests the next 7 days ... but early in the morning, there aren't this many days forecast by bom, it returns 'None' in last day.\n",
    "        # So just copy the prev day's prediction. \n",
    "        if temps[-1] is None: temps[-1] = temps[-2] \n",
    "        #  if today is missing (not sure if that actually happens) then replace it with observed data from today\n",
    "        if temps[0] is None: temps[0] = max_temp_today\n",
    "        # temps[0] = max(temps[0], max_temp_today)  # don't do this because observations may be for yesterday (they are at 1am)\n",
    "        \n",
    "        assert None not in temps, f\"something has gone wrong with weather forecast data for {region}. Max temps are {temps}\"\n",
    "        assert len(temps) == 8, f\"there should be 8 forecast {region} temperatures but there are {len(temps)}\"\n",
    "\n",
    "        temp_names = ['RG_W_day_max_temperature', 'RG_W_day_max_temperature_Tp24', 'RG_W_day_max_temperature_Tp48', 'RG_W_day_max_temperature_Tp72', 'RG_W_day_max_temperature_Tp96', 'RG_W_day_max_temperature_Tp120', 'RG_W_day_max_temperature_Tp144', 'RG_W_day_max_temperature_Tp168']\n",
    "        temp_names = [x.replace('RG', region) for x in temp_names]\n",
    "        \n",
    "        for name, temp in list(zip(temp_names, temps)):\n",
    "            output[name] = temp\n",
    "\n",
    "    return output\n",
    "\n",
    "features = features | get_weather_features()\n",
    "features\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd41d3c-13fb-409d-80a3-9b2bfd9b2560",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Price & Generation by region\n",
    "\n",
    "Various sub-tables of \"Dispatch\", which are equivalent of `DISPATCHREGIONSUM`, `DISPATCHPRICE` and `DISPATCHINTERCONNECTORRES` in the dataset generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94c18a-fc8a-4a6c-93e3-442167821dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_price_and_gen():\n",
    "    \"\"\"Get Price & Generation features by region\n",
    "\n",
    "    Downloads various sub-tables of \"Dispatch\", which are equivalent of `DISPATCHREGIONSUM`, \n",
    "    `DISPATCHPRICE` and `DISPATCHINTERCONNECTORRES` in the dataset generator.\n",
    "    \"\"\"\n",
    "    filename = get_latest_file_from_folder('DispatchIS_Reports')\n",
    "\n",
    "    # price features\n",
    "    price_table = pd.read_csv(get_subtable_from_file(filename, 'DISPATCH,PRICE,'), \n",
    "                              index_col='REGIONID', usecols=['REGIONID', 'RRP'])\n",
    "    for region in REGIONIDS:\n",
    "        features[f'{region}_Price'] = price_table.at[region, 'RRP']\n",
    "\n",
    "    # regionsum features aka 'DISPATCHREGIONSUM' aka 'Generation For Each Region'\n",
    "    regionsum_table = pd.read_csv(get_subtable_from_file(filename, 'DISPATCH,REGIONSUM,'),\n",
    "                                  index_col='REGIONID', \n",
    "                                  usecols=['REGIONID', 'AVAILABLEGENERATION', 'TOTALDEMAND', 'DISPATCHABLEGENERATION', 'NETINTERCHANGE'])\n",
    "    # IC_NET is defined to be NETINTERCHANGE * -1. IC_NET: import is +ve generation.\n",
    "    regionsum_table['NETINTERCHANGE'] = regionsum_table['NETINTERCHANGE'] * -1\n",
    "    regionsum_table = regionsum_table.rename(columns={'NETINTERCHANGE': 'IC_NET', 'DISPATCHABLEGENERATION': 'GENERATION' })\n",
    "    for region in REGIONIDS:\n",
    "        for col in regionsum_table.columns:\n",
    "            features[f'{region}_{col}'] = regionsum_table.at[region, col]\n",
    "\n",
    "    # Interconnector import / export limits\n",
    "    ic_table = pd.read_csv(get_subtable_from_file(filename, 'DISPATCH,INTERCONNECTORRES,'), \n",
    "                           usecols=['INTERCONNECTORID', 'EXPORTLIMIT', 'IMPORTLIMIT'], \n",
    "                           index_col='INTERCONNECTORID')\n",
    "    # manually convert each interconnector data to region summaries\n",
    "    features['VIC1_IC_Import_Limit'] = (- ic_table.at['T-V-MNSP1', 'EXPORTLIMIT'] + ic_table.at['V-S-MNSP1', 'IMPORTLIMIT'] + ic_table.at['V-SA', 'IMPORTLIMIT'] + ic_table.at['VIC1-NSW1', 'IMPORTLIMIT']) * -1\n",
    "    features['VIC1_IC_Export_Limit'] = (- ic_table.at['T-V-MNSP1', 'IMPORTLIMIT'] + ic_table.at['V-S-MNSP1', 'EXPORTLIMIT'] + ic_table.at['V-SA', 'EXPORTLIMIT'] + ic_table.at['VIC1-NSW1', 'EXPORTLIMIT']) * -1\n",
    "    features['TAS1_IC_Import_Limit'] = ic_table.at['T-V-MNSP1', 'IMPORTLIMIT'] * -1\n",
    "    features['TAS1_IC_Export_Limit'] = ic_table.at['T-V-MNSP1', 'EXPORTLIMIT'] * -1\n",
    "    features['SA1_IC_Import_Limit']  = (- ic_table.at['V-S-MNSP1', 'EXPORTLIMIT'] - ic_table.at['V-SA', 'EXPORTLIMIT']) * -1\n",
    "    features['SA1_IC_Export_Limit']  = (- ic_table.at['V-S-MNSP1', 'IMPORTLIMIT'] - ic_table.at['V-SA', 'IMPORTLIMIT']) * -1\n",
    "    features['NSW1_IC_Import_Limit'] = (- ic_table.at['VIC1-NSW1', 'EXPORTLIMIT'] + ic_table.at['NSW1-QLD1', 'IMPORTLIMIT'] + ic_table.at['N-Q-MNSP1', 'IMPORTLIMIT']) * -1\n",
    "    features['NSW1_IC_Export_Limit'] = (- ic_table.at['VIC1-NSW1', 'IMPORTLIMIT'] + ic_table.at['NSW1-QLD1', 'EXPORTLIMIT'] + ic_table.at['N-Q-MNSP1', 'EXPORTLIMIT']) * -1\n",
    "    features['QLD1_IC_Import_Limit'] = (- ic_table.at['NSW1-QLD1', 'EXPORTLIMIT'] - ic_table.at['N-Q-MNSP1', 'EXPORTLIMIT']) * -1\n",
    "    features['QLD1_IC_Export_Limit'] = (- ic_table.at['NSW1-QLD1', 'IMPORTLIMIT'] - ic_table.at['N-Q-MNSP1', 'IMPORTLIMIT']) * -1\n",
    "    return features\n",
    "features = features | get_price_and_gen()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634655d5-6474-4fe1-a574-2f5f1fd0793b",
   "metadata": {},
   "source": [
    "## Price Lags - up to 30d in the past"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5175305-609b-449a-86e4-b29b95bb259a",
   "metadata": {},
   "source": [
    "The last 24 hours of lags aren't necessarily in the daily reports, so get them from 5-minute reports. \n",
    "\n",
    "Note: Not bothering to do any averaging across the whole hour, just instantaneous 5-min values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779b952-e400-4c30-94df-118787c05267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_price_lags():\n",
    "    \"\"\"Get all the price lag features.\"\"\"\n",
    "    output = {}\n",
    "\n",
    "    # The last 24 hours of lags aren't necessarily in the daily reports, so get them from 5-minute reports.\n",
    "    # Note: Not bothering to do any averaging across the whole hour, just instantaneous 5-min values.\n",
    "    lags = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n",
    "    targets = [f'RG_Price_Tm{hours}' for hours in lags]\n",
    "    for lag in lags:\n",
    "        filename = get_latest_file_from_folder('TradingIS_Reports', nth_most_recent=-1*lag*12)\n",
    "        df = pd.read_csv(get_subtable_from_file(filename, ',TRADING,PRICE,'),\n",
    "                         usecols=['REGIONID', 'RRP', ],\n",
    "                         index_col='REGIONID'\n",
    "                        )\n",
    "        for region in REGIONIDS:\n",
    "            output[f\"{region}_Price_Tm{lag}\"] = df.at[region, 'RRP']\n",
    "            \n",
    "    # Get the remaining lags up to 30 days ago from the daily reports\n",
    "    # 'RG_Price_Tm28', 'RG_Price_Tm32',... 'RG_Price_Tm168',\n",
    "    # 'RG_Price_Tm30d_25thP', 'RG_Price_Tm30d_Median', 'RG_Price_Tm30d_75thP', 'RG_Price_Tm30d_Mean'\n",
    "    # Firest, get last 30 days of daily reports:\n",
    "    filenames =[get_latest_file_from_folder('Daily_Reports', nth_most_recent=i) \n",
    "                for i in range(-1, -31, -1)]\n",
    "\n",
    "    # Get prices, averaged to hourly, for the last 30 days\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        df = pd.read_csv(get_subtable_from_file(filename, ',DREGION,,3'),\n",
    "                         usecols=['REGIONID', 'RRP', 'SETTLEMENTDATE', ],\n",
    "                         parse_dates=['SETTLEMENTDATE'],\n",
    "                         index_col='SETTLEMENTDATE'\n",
    "                        )\n",
    "        df = df.pivot(columns='REGIONID', values='RRP')\n",
    "        # change from 5min to 60min frequency to match PV_forecast\n",
    "        df = df.resample('H', origin='start').mean()\n",
    "        df.index = df.index + pd.tseries.frequencies.to_offset('55min')  # because SETTLEMENTDATE is end-of-period\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    # concat all\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    ### outputs:\n",
    "\n",
    "    # 'RG_Price_Tm28', 'RG_Price_Tm32',... 'RG_Price_Tm168',\n",
    "    for lag in [28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 168]:\n",
    "        for region in REGIONIDS:\n",
    "            output[f\"{region}_Price_Tm{lag}\"] = df.at[pd.Timestamp.now().round('H') - pd.Timedelta(lag, 'H'), region]\n",
    "    \n",
    "    # 'RG_Price_Tm7d_25thP', 'RG_Price_Tm7d_Median', 'RG_Price_Tm7d_75thP'\n",
    "    for region in REGIONIDS:\n",
    "        last_7_days = df[region][df.index > pd.Timestamp.now() - pd.Timedelta(7, 'D')]\n",
    "        output[f'{region}_Price_Tm7d_15thP'] = last_7_days.quantile(0.15)\n",
    "        output[f'{region}_Price_Tm7d_Median'] = last_7_days.quantile(0.5)\n",
    "        output[f'{region}_Price_Tm7d_85thP'] = last_7_days.quantile(0.85)\n",
    "\n",
    "    # 'RG_Price_Tm30d_25thP', 'RG_Price_Tm30d_Median', 'RG_Price_Tm30d_75thP'\n",
    "    for region in REGIONIDS:\n",
    "        output[f'{region}_Price_Tm30d_15thP'] = df[region].quantile(0.15)\n",
    "        output[f'{region}_Price_Tm30d_Median'] = df[region].quantile(0.5)\n",
    "        output[f'{region}_Price_Tm30d_85thP'] = df[region].quantile(0.85)\n",
    "    \n",
    "    return output\n",
    "\n",
    "features = features | get_price_lags()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945f362-345e-4413-a351-e4a1d479f775",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-dispatch Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f9652-8dbc-4ebe-a1c6-d4d0dcb99000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predispatch_prices():\n",
    "    \"\"\"Get predispatch price prediction features\n",
    "    \n",
    "    'VIC1_Predis_Price_Tp4', 'VIC1_Predis_Price_Tp8', 'VIC1_Predis_Price_Tp12',  'VIC1_Predis_Price_Tp16',\n",
    "    'VIC1_Predis_Price_max16to40h', 'VIC1_Predis_Price_min16to40h'\n",
    "    \"\"\"\n",
    "    filename = get_latest_file_from_folder('PredispatchIS_Reports')\n",
    "    df = pd.read_csv(get_subtable_from_file(filename, 'PREDISPATCH,REGION_PRICES'),\n",
    "                     usecols=['REGIONID', 'RRP', 'DATETIME'],\n",
    "                     parse_dates=['DATETIME'],)\n",
    "                     # index_col='DATETIME')\n",
    "\n",
    "    # removes final rows with NAs\n",
    "    print(df.shape)\n",
    "    # Duplicated rows ... probably because of multiple (types of?) runs for same period. Keep only the last ones. \n",
    "    df = df.drop_duplicates(['DATETIME', 'REGIONID'], keep='last')\n",
    "    # Don't need half-hourly, hourly is fine, drop the other rows\n",
    "    df = df[df['DATETIME'].dt.minute == 0]\n",
    "\n",
    "    # do the pivot\n",
    "    now = df.iloc[0].DATETIME\n",
    "    df['Forecast_Distance'] = df['DATETIME'] - now\n",
    "    df = df.pivot(index='Forecast_Distance', \n",
    "                  columns='REGIONID',\n",
    "                  values='RRP'\n",
    "                 ).sort_index(axis=1, level='REGIONID')\n",
    "    df.index = df.index.total_seconds() // 3600\n",
    "\n",
    "    output = {}\n",
    "    for region in REGIONIDS:\n",
    "        for lag in [4, 8, 12, 16]:\n",
    "            output[f'{region}_Predis_Price_Tp{lag}'] = df[region].loc[lag]\n",
    "        output[f'{region}_Predis_Price_max16to40h'] = df[region].loc[16:44].max()\n",
    "        output[f'{region}_Predis_Price_min16to40h'] = df[region].loc[16:44].min()\n",
    "    return output\n",
    "features = features | get_predispatch_prices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7acbe-4b94-4796-8569-463a320cdd87",
   "metadata": {},
   "source": [
    "## Forecasts of Price & Gen by Region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7104f398-560e-4cf8-b8b3-a8bce65b395b",
   "metadata": {},
   "source": [
    "Requires a combination of pre-dispatch (for the next day-or-so) and STPASA (which starts at 4.30am on day after next trading day)\n",
    "- 'RG_AVAILABLEGENERATION_Tp6', 'RG_AVAILABLEGENERATION_Tp12'...'RG_AVAILABLEGENERATION_Tp168', \n",
    "- 'RG_TOTALDEMAND_Tp6', 'RG_TOTALDEMAND_Tp12'... 'RG_TOTALDEMAND_Tp168', \n",
    "- 'RG_GEN_Solar_Tp6', 'RG_GEN_Solar_Tp12', ... 'RG_GEN_Solar_Tp168', \n",
    "- 'RG_GEN_Wind_Tp6', 'RG_GEN_Wind_Tp12', ... 'RG_GEN_Wind_Tp168', \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0afc96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NSW1_AVAILABLEGENERATION</th>\n",
       "      <th>QLD1_AVAILABLEGENERATION</th>\n",
       "      <th>SA1_AVAILABLEGENERATION</th>\n",
       "      <th>TAS1_AVAILABLEGENERATION</th>\n",
       "      <th>VIC1_AVAILABLEGENERATION</th>\n",
       "      <th>NSW1_TOTALDEMAND</th>\n",
       "      <th>QLD1_TOTALDEMAND</th>\n",
       "      <th>SA1_TOTALDEMAND</th>\n",
       "      <th>TAS1_TOTALDEMAND</th>\n",
       "      <th>VIC1_TOTALDEMAND</th>\n",
       "      <th>NSW1_GEN_Solar</th>\n",
       "      <th>QLD1_GEN_Solar</th>\n",
       "      <th>SA1_GEN_Solar</th>\n",
       "      <th>TAS1_GEN_Solar</th>\n",
       "      <th>VIC1_GEN_Solar</th>\n",
       "      <th>NSW1_GEN_Wind</th>\n",
       "      <th>QLD1_GEN_Wind</th>\n",
       "      <th>SA1_GEN_Wind</th>\n",
       "      <th>TAS1_GEN_Wind</th>\n",
       "      <th>VIC1_GEN_Wind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-05 12:30:00</th>\n",
       "      <td>10765.050</td>\n",
       "      <td>8946.387</td>\n",
       "      <td>1934.369</td>\n",
       "      <td>2240.866</td>\n",
       "      <td>9076.913</td>\n",
       "      <td>8130.350</td>\n",
       "      <td>5009.350</td>\n",
       "      <td>1166.470</td>\n",
       "      <td>1104.000</td>\n",
       "      <td>5456.200</td>\n",
       "      <td>496.022</td>\n",
       "      <td>1321.744</td>\n",
       "      <td>220.511</td>\n",
       "      <td>0.000</td>\n",
       "      <td>137.262</td>\n",
       "      <td>1211.028</td>\n",
       "      <td>154.643</td>\n",
       "      <td>296.858</td>\n",
       "      <td>211.866</td>\n",
       "      <td>2116.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 13:00:00</th>\n",
       "      <td>10717.369</td>\n",
       "      <td>8906.408</td>\n",
       "      <td>2014.529</td>\n",
       "      <td>2235.231</td>\n",
       "      <td>8774.439</td>\n",
       "      <td>8102.040</td>\n",
       "      <td>5065.500</td>\n",
       "      <td>1133.430</td>\n",
       "      <td>1077.000</td>\n",
       "      <td>5401.020</td>\n",
       "      <td>447.007</td>\n",
       "      <td>1291.293</td>\n",
       "      <td>227.712</td>\n",
       "      <td>0.000</td>\n",
       "      <td>126.049</td>\n",
       "      <td>1212.362</td>\n",
       "      <td>142.115</td>\n",
       "      <td>368.817</td>\n",
       "      <td>206.231</td>\n",
       "      <td>2107.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 13:30:00</th>\n",
       "      <td>10715.147</td>\n",
       "      <td>8972.115</td>\n",
       "      <td>2063.701</td>\n",
       "      <td>2205.494</td>\n",
       "      <td>8940.591</td>\n",
       "      <td>8119.820</td>\n",
       "      <td>5215.050</td>\n",
       "      <td>1063.250</td>\n",
       "      <td>1046.000</td>\n",
       "      <td>5379.560</td>\n",
       "      <td>439.765</td>\n",
       "      <td>1208.926</td>\n",
       "      <td>237.183</td>\n",
       "      <td>0.000</td>\n",
       "      <td>128.198</td>\n",
       "      <td>1216.382</td>\n",
       "      <td>145.189</td>\n",
       "      <td>410.518</td>\n",
       "      <td>204.494</td>\n",
       "      <td>2115.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 14:00:00</th>\n",
       "      <td>10701.405</td>\n",
       "      <td>8902.548</td>\n",
       "      <td>2091.244</td>\n",
       "      <td>2203.250</td>\n",
       "      <td>8956.163</td>\n",
       "      <td>8158.600</td>\n",
       "      <td>5373.160</td>\n",
       "      <td>1028.240</td>\n",
       "      <td>1035.000</td>\n",
       "      <td>5372.330</td>\n",
       "      <td>417.931</td>\n",
       "      <td>1081.243</td>\n",
       "      <td>235.381</td>\n",
       "      <td>0.000</td>\n",
       "      <td>130.048</td>\n",
       "      <td>1223.474</td>\n",
       "      <td>151.305</td>\n",
       "      <td>442.863</td>\n",
       "      <td>202.250</td>\n",
       "      <td>2129.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 14:30:00</th>\n",
       "      <td>10866.202</td>\n",
       "      <td>8779.424</td>\n",
       "      <td>2121.812</td>\n",
       "      <td>2226.560</td>\n",
       "      <td>8969.685</td>\n",
       "      <td>8195.880</td>\n",
       "      <td>5535.740</td>\n",
       "      <td>1005.640</td>\n",
       "      <td>1028.000</td>\n",
       "      <td>5365.550</td>\n",
       "      <td>384.167</td>\n",
       "      <td>941.403</td>\n",
       "      <td>225.720</td>\n",
       "      <td>0.000</td>\n",
       "      <td>124.838</td>\n",
       "      <td>1226.035</td>\n",
       "      <td>163.021</td>\n",
       "      <td>468.092</td>\n",
       "      <td>203.560</td>\n",
       "      <td>2148.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 15:00:00</th>\n",
       "      <td>10821.944</td>\n",
       "      <td>8987.615</td>\n",
       "      <td>2148.397</td>\n",
       "      <td>2228.309</td>\n",
       "      <td>9276.916</td>\n",
       "      <td>8281.450</td>\n",
       "      <td>5745.930</td>\n",
       "      <td>1002.610</td>\n",
       "      <td>1032.000</td>\n",
       "      <td>5411.890</td>\n",
       "      <td>337.472</td>\n",
       "      <td>805.239</td>\n",
       "      <td>230.460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>116.731</td>\n",
       "      <td>1228.472</td>\n",
       "      <td>177.376</td>\n",
       "      <td>490.937</td>\n",
       "      <td>205.309</td>\n",
       "      <td>2187.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 15:30:00</th>\n",
       "      <td>10780.983</td>\n",
       "      <td>8782.219</td>\n",
       "      <td>2353.836</td>\n",
       "      <td>2348.513</td>\n",
       "      <td>9406.074</td>\n",
       "      <td>8403.700</td>\n",
       "      <td>5950.120</td>\n",
       "      <td>1031.530</td>\n",
       "      <td>1044.000</td>\n",
       "      <td>5496.090</td>\n",
       "      <td>291.108</td>\n",
       "      <td>565.523</td>\n",
       "      <td>264.814</td>\n",
       "      <td>0.000</td>\n",
       "      <td>105.547</td>\n",
       "      <td>1241.875</td>\n",
       "      <td>209.696</td>\n",
       "      <td>511.022</td>\n",
       "      <td>207.513</td>\n",
       "      <td>2267.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 16:00:00</th>\n",
       "      <td>10942.025</td>\n",
       "      <td>9106.621</td>\n",
       "      <td>2426.478</td>\n",
       "      <td>2367.113</td>\n",
       "      <td>9445.230</td>\n",
       "      <td>8559.040</td>\n",
       "      <td>6204.390</td>\n",
       "      <td>1069.000</td>\n",
       "      <td>1073.000</td>\n",
       "      <td>5587.400</td>\n",
       "      <td>239.314</td>\n",
       "      <td>450.004</td>\n",
       "      <td>260.899</td>\n",
       "      <td>0.000</td>\n",
       "      <td>91.830</td>\n",
       "      <td>1224.711</td>\n",
       "      <td>224.617</td>\n",
       "      <td>532.579</td>\n",
       "      <td>211.113</td>\n",
       "      <td>2313.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 16:30:00</th>\n",
       "      <td>11032.221</td>\n",
       "      <td>9433.925</td>\n",
       "      <td>2433.195</td>\n",
       "      <td>2431.000</td>\n",
       "      <td>9466.678</td>\n",
       "      <td>8704.340</td>\n",
       "      <td>6436.840</td>\n",
       "      <td>1140.100</td>\n",
       "      <td>1103.000</td>\n",
       "      <td>5715.050</td>\n",
       "      <td>171.940</td>\n",
       "      <td>319.109</td>\n",
       "      <td>251.468</td>\n",
       "      <td>0.000</td>\n",
       "      <td>75.270</td>\n",
       "      <td>1238.281</td>\n",
       "      <td>232.816</td>\n",
       "      <td>487.727</td>\n",
       "      <td>217.000</td>\n",
       "      <td>2334.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 17:00:00</th>\n",
       "      <td>11013.811</td>\n",
       "      <td>9307.386</td>\n",
       "      <td>2450.111</td>\n",
       "      <td>2435.960</td>\n",
       "      <td>9487.960</td>\n",
       "      <td>8890.890</td>\n",
       "      <td>6690.900</td>\n",
       "      <td>1234.040</td>\n",
       "      <td>1146.000</td>\n",
       "      <td>5855.500</td>\n",
       "      <td>117.174</td>\n",
       "      <td>179.303</td>\n",
       "      <td>229.213</td>\n",
       "      <td>0.000</td>\n",
       "      <td>56.418</td>\n",
       "      <td>1274.637</td>\n",
       "      <td>243.083</td>\n",
       "      <td>446.898</td>\n",
       "      <td>221.960</td>\n",
       "      <td>2373.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 17:30:00</th>\n",
       "      <td>10987.648</td>\n",
       "      <td>9204.221</td>\n",
       "      <td>2428.511</td>\n",
       "      <td>2445.778</td>\n",
       "      <td>9570.562</td>\n",
       "      <td>9014.060</td>\n",
       "      <td>6863.580</td>\n",
       "      <td>1344.370</td>\n",
       "      <td>1184.000</td>\n",
       "      <td>5917.010</td>\n",
       "      <td>72.320</td>\n",
       "      <td>66.381</td>\n",
       "      <td>180.502</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.950</td>\n",
       "      <td>1293.328</td>\n",
       "      <td>252.840</td>\n",
       "      <td>414.009</td>\n",
       "      <td>231.778</td>\n",
       "      <td>2394.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 18:00:00</th>\n",
       "      <td>10963.472</td>\n",
       "      <td>9157.287</td>\n",
       "      <td>2355.004</td>\n",
       "      <td>2451.627</td>\n",
       "      <td>9578.846</td>\n",
       "      <td>9146.570</td>\n",
       "      <td>6993.540</td>\n",
       "      <td>1441.320</td>\n",
       "      <td>1208.000</td>\n",
       "      <td>5909.840</td>\n",
       "      <td>24.681</td>\n",
       "      <td>8.794</td>\n",
       "      <td>115.122</td>\n",
       "      <td>0.000</td>\n",
       "      <td>19.983</td>\n",
       "      <td>1316.791</td>\n",
       "      <td>260.493</td>\n",
       "      <td>372.882</td>\n",
       "      <td>237.627</td>\n",
       "      <td>2415.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 18:30:00</th>\n",
       "      <td>10957.351</td>\n",
       "      <td>9152.357</td>\n",
       "      <td>2248.055</td>\n",
       "      <td>2457.496</td>\n",
       "      <td>9546.963</td>\n",
       "      <td>9184.820</td>\n",
       "      <td>7080.900</td>\n",
       "      <td>1529.980</td>\n",
       "      <td>1230.000</td>\n",
       "      <td>5880.340</td>\n",
       "      <td>2.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>39.751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.903</td>\n",
       "      <td>1337.424</td>\n",
       "      <td>264.325</td>\n",
       "      <td>339.304</td>\n",
       "      <td>243.496</td>\n",
       "      <td>2435.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 19:00:00</th>\n",
       "      <td>10969.437</td>\n",
       "      <td>9161.549</td>\n",
       "      <td>2190.302</td>\n",
       "      <td>2468.959</td>\n",
       "      <td>9517.895</td>\n",
       "      <td>9110.350</td>\n",
       "      <td>7096.910</td>\n",
       "      <td>1587.120</td>\n",
       "      <td>1243.000</td>\n",
       "      <td>5882.850</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1352.309</td>\n",
       "      <td>270.549</td>\n",
       "      <td>318.970</td>\n",
       "      <td>254.959</td>\n",
       "      <td>2450.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 19:30:00</th>\n",
       "      <td>10978.760</td>\n",
       "      <td>9173.031</td>\n",
       "      <td>2200.918</td>\n",
       "      <td>2471.585</td>\n",
       "      <td>9521.605</td>\n",
       "      <td>8908.290</td>\n",
       "      <td>6963.930</td>\n",
       "      <td>1619.130</td>\n",
       "      <td>1235.000</td>\n",
       "      <td>5825.230</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1361.760</td>\n",
       "      <td>292.031</td>\n",
       "      <td>311.909</td>\n",
       "      <td>257.585</td>\n",
       "      <td>2459.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 20:00:00</th>\n",
       "      <td>10989.762</td>\n",
       "      <td>9180.284</td>\n",
       "      <td>2195.339</td>\n",
       "      <td>2474.750</td>\n",
       "      <td>9479.764</td>\n",
       "      <td>8746.420</td>\n",
       "      <td>6913.010</td>\n",
       "      <td>1608.020</td>\n",
       "      <td>1220.000</td>\n",
       "      <td>5800.510</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1368.762</td>\n",
       "      <td>312.284</td>\n",
       "      <td>307.330</td>\n",
       "      <td>260.750</td>\n",
       "      <td>2454.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 20:30:00</th>\n",
       "      <td>10941.685</td>\n",
       "      <td>9177.259</td>\n",
       "      <td>2188.362</td>\n",
       "      <td>2477.720</td>\n",
       "      <td>9607.434</td>\n",
       "      <td>8550.960</td>\n",
       "      <td>6894.280</td>\n",
       "      <td>1556.730</td>\n",
       "      <td>1203.000</td>\n",
       "      <td>5606.780</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1370.685</td>\n",
       "      <td>329.259</td>\n",
       "      <td>300.353</td>\n",
       "      <td>263.720</td>\n",
       "      <td>2451.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 21:00:00</th>\n",
       "      <td>10942.736</td>\n",
       "      <td>9057.542</td>\n",
       "      <td>2182.931</td>\n",
       "      <td>2479.754</td>\n",
       "      <td>9599.540</td>\n",
       "      <td>8284.340</td>\n",
       "      <td>6764.630</td>\n",
       "      <td>1518.810</td>\n",
       "      <td>1173.000</td>\n",
       "      <td>5378.170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1371.736</td>\n",
       "      <td>349.542</td>\n",
       "      <td>296.922</td>\n",
       "      <td>265.754</td>\n",
       "      <td>2455.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 21:30:00</th>\n",
       "      <td>10527.590</td>\n",
       "      <td>9134.647</td>\n",
       "      <td>2180.053</td>\n",
       "      <td>2481.666</td>\n",
       "      <td>9741.893</td>\n",
       "      <td>8117.000</td>\n",
       "      <td>6573.060</td>\n",
       "      <td>1469.660</td>\n",
       "      <td>1137.000</td>\n",
       "      <td>5120.510</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1371.590</td>\n",
       "      <td>390.647</td>\n",
       "      <td>295.044</td>\n",
       "      <td>267.666</td>\n",
       "      <td>2454.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 22:00:00</th>\n",
       "      <td>10525.981</td>\n",
       "      <td>9005.847</td>\n",
       "      <td>2177.088</td>\n",
       "      <td>2455.354</td>\n",
       "      <td>9871.805</td>\n",
       "      <td>7944.400</td>\n",
       "      <td>6384.420</td>\n",
       "      <td>1423.070</td>\n",
       "      <td>1100.000</td>\n",
       "      <td>4870.930</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1369.981</td>\n",
       "      <td>424.847</td>\n",
       "      <td>294.079</td>\n",
       "      <td>269.354</td>\n",
       "      <td>2452.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 22:30:00</th>\n",
       "      <td>9928.019</td>\n",
       "      <td>8672.081</td>\n",
       "      <td>2151.334</td>\n",
       "      <td>2459.706</td>\n",
       "      <td>10009.565</td>\n",
       "      <td>7857.520</td>\n",
       "      <td>6172.690</td>\n",
       "      <td>1377.810</td>\n",
       "      <td>1061.000</td>\n",
       "      <td>4654.870</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1372.019</td>\n",
       "      <td>428.081</td>\n",
       "      <td>268.325</td>\n",
       "      <td>273.706</td>\n",
       "      <td>2444.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 23:00:00</th>\n",
       "      <td>9926.465</td>\n",
       "      <td>8416.603</td>\n",
       "      <td>2133.424</td>\n",
       "      <td>2462.766</td>\n",
       "      <td>10129.879</td>\n",
       "      <td>7697.190</td>\n",
       "      <td>6016.290</td>\n",
       "      <td>1337.350</td>\n",
       "      <td>1037.000</td>\n",
       "      <td>4487.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1370.465</td>\n",
       "      <td>425.603</td>\n",
       "      <td>245.415</td>\n",
       "      <td>276.766</td>\n",
       "      <td>2433.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-05 23:30:00</th>\n",
       "      <td>9905.220</td>\n",
       "      <td>8565.761</td>\n",
       "      <td>2109.869</td>\n",
       "      <td>2466.669</td>\n",
       "      <td>10116.282</td>\n",
       "      <td>7556.560</td>\n",
       "      <td>5902.130</td>\n",
       "      <td>1320.450</td>\n",
       "      <td>1016.000</td>\n",
       "      <td>4519.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1349.220</td>\n",
       "      <td>416.761</td>\n",
       "      <td>220.860</td>\n",
       "      <td>280.669</td>\n",
       "      <td>2419.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-06 00:00:00</th>\n",
       "      <td>9895.119</td>\n",
       "      <td>8548.805</td>\n",
       "      <td>2089.799</td>\n",
       "      <td>2470.536</td>\n",
       "      <td>10101.510</td>\n",
       "      <td>7471.640</td>\n",
       "      <td>5742.510</td>\n",
       "      <td>1415.340</td>\n",
       "      <td>1004.000</td>\n",
       "      <td>4484.660</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1339.119</td>\n",
       "      <td>399.805</td>\n",
       "      <td>199.790</td>\n",
       "      <td>284.536</td>\n",
       "      <td>2402.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-06 00:30:00</th>\n",
       "      <td>9864.474</td>\n",
       "      <td>8537.013</td>\n",
       "      <td>2076.134</td>\n",
       "      <td>2474.937</td>\n",
       "      <td>10070.088</td>\n",
       "      <td>7327.160</td>\n",
       "      <td>5531.570</td>\n",
       "      <td>1394.160</td>\n",
       "      <td>999.000</td>\n",
       "      <td>4347.710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1308.474</td>\n",
       "      <td>388.013</td>\n",
       "      <td>186.125</td>\n",
       "      <td>288.937</td>\n",
       "      <td>2371.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-06 01:00:00</th>\n",
       "      <td>9839.444</td>\n",
       "      <td>8527.932</td>\n",
       "      <td>2070.380</td>\n",
       "      <td>2477.533</td>\n",
       "      <td>10063.533</td>\n",
       "      <td>7165.040</td>\n",
       "      <td>5397.170</td>\n",
       "      <td>1396.280</td>\n",
       "      <td>998.000</td>\n",
       "      <td>4209.140</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1283.444</td>\n",
       "      <td>377.932</td>\n",
       "      <td>176.371</td>\n",
       "      <td>291.533</td>\n",
       "      <td>2350.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-06 01:30:00</th>\n",
       "      <td>9807.906</td>\n",
       "      <td>8516.007</td>\n",
       "      <td>2067.027</td>\n",
       "      <td>2482.634</td>\n",
       "      <td>10008.691</td>\n",
       "      <td>6917.770</td>\n",
       "      <td>5301.420</td>\n",
       "      <td>1353.410</td>\n",
       "      <td>996.000</td>\n",
       "      <td>4077.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1251.906</td>\n",
       "      <td>368.007</td>\n",
       "      <td>173.018</td>\n",
       "      <td>296.634</td>\n",
       "      <td>2300.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-06 02:00:00</th>\n",
       "      <td>9782.642</td>\n",
       "      <td>8509.850</td>\n",
       "      <td>2065.007</td>\n",
       "      <td>2488.404</td>\n",
       "      <td>9960.477</td>\n",
       "      <td>6679.210</td>\n",
       "      <td>5224.390</td>\n",
       "      <td>1304.560</td>\n",
       "      <td>997.000</td>\n",
       "      <td>3956.690</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1226.642</td>\n",
       "      <td>359.850</td>\n",
       "      <td>170.998</td>\n",
       "      <td>302.404</td>\n",
       "      <td>2251.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-06 02:30:00</th>\n",
       "      <td>9755.195</td>\n",
       "      <td>8503.090</td>\n",
       "      <td>2067.841</td>\n",
       "      <td>2494.909</td>\n",
       "      <td>9922.643</td>\n",
       "      <td>6461.490</td>\n",
       "      <td>5169.350</td>\n",
       "      <td>1259.640</td>\n",
       "      <td>992.000</td>\n",
       "      <td>3872.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1199.195</td>\n",
       "      <td>351.090</td>\n",
       "      <td>169.832</td>\n",
       "      <td>308.909</td>\n",
       "      <td>2208.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-06 03:00:00</th>\n",
       "      <td>9725.836</td>\n",
       "      <td>8494.012</td>\n",
       "      <td>2066.686</td>\n",
       "      <td>2500.336</td>\n",
       "      <td>9883.984</td>\n",
       "      <td>6310.270</td>\n",
       "      <td>5144.250</td>\n",
       "      <td>1230.640</td>\n",
       "      <td>1006.000</td>\n",
       "      <td>3827.410</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1169.836</td>\n",
       "      <td>342.012</td>\n",
       "      <td>170.677</td>\n",
       "      <td>314.336</td>\n",
       "      <td>2159.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-06 03:30:00</th>\n",
       "      <td>9698.191</td>\n",
       "      <td>8489.970</td>\n",
       "      <td>2072.697</td>\n",
       "      <td>2505.865</td>\n",
       "      <td>9834.786</td>\n",
       "      <td>6272.070</td>\n",
       "      <td>5140.160</td>\n",
       "      <td>1207.260</td>\n",
       "      <td>1016.000</td>\n",
       "      <td>3823.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1137.191</td>\n",
       "      <td>335.970</td>\n",
       "      <td>175.688</td>\n",
       "      <td>319.865</td>\n",
       "      <td>2099.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-06 04:00:00</th>\n",
       "      <td>9660.177</td>\n",
       "      <td>8478.136</td>\n",
       "      <td>2077.988</td>\n",
       "      <td>2512.819</td>\n",
       "      <td>9711.467</td>\n",
       "      <td>6303.360</td>\n",
       "      <td>5161.190</td>\n",
       "      <td>1196.570</td>\n",
       "      <td>1029.000</td>\n",
       "      <td>3870.140</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1099.177</td>\n",
       "      <td>323.136</td>\n",
       "      <td>180.979</td>\n",
       "      <td>326.819</td>\n",
       "      <td>2038.467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NSW1_AVAILABLEGENERATION  QLD1_AVAILABLEGENERATION  \\\n",
       "DATETIME                                                                  \n",
       "2022-10-05 12:30:00                 10765.050                  8946.387   \n",
       "2022-10-05 13:00:00                 10717.369                  8906.408   \n",
       "2022-10-05 13:30:00                 10715.147                  8972.115   \n",
       "2022-10-05 14:00:00                 10701.405                  8902.548   \n",
       "2022-10-05 14:30:00                 10866.202                  8779.424   \n",
       "2022-10-05 15:00:00                 10821.944                  8987.615   \n",
       "2022-10-05 15:30:00                 10780.983                  8782.219   \n",
       "2022-10-05 16:00:00                 10942.025                  9106.621   \n",
       "2022-10-05 16:30:00                 11032.221                  9433.925   \n",
       "2022-10-05 17:00:00                 11013.811                  9307.386   \n",
       "2022-10-05 17:30:00                 10987.648                  9204.221   \n",
       "2022-10-05 18:00:00                 10963.472                  9157.287   \n",
       "2022-10-05 18:30:00                 10957.351                  9152.357   \n",
       "2022-10-05 19:00:00                 10969.437                  9161.549   \n",
       "2022-10-05 19:30:00                 10978.760                  9173.031   \n",
       "2022-10-05 20:00:00                 10989.762                  9180.284   \n",
       "2022-10-05 20:30:00                 10941.685                  9177.259   \n",
       "2022-10-05 21:00:00                 10942.736                  9057.542   \n",
       "2022-10-05 21:30:00                 10527.590                  9134.647   \n",
       "2022-10-05 22:00:00                 10525.981                  9005.847   \n",
       "2022-10-05 22:30:00                  9928.019                  8672.081   \n",
       "2022-10-05 23:00:00                  9926.465                  8416.603   \n",
       "2022-10-05 23:30:00                  9905.220                  8565.761   \n",
       "2022-10-06 00:00:00                  9895.119                  8548.805   \n",
       "2022-10-06 00:30:00                  9864.474                  8537.013   \n",
       "2022-10-06 01:00:00                  9839.444                  8527.932   \n",
       "2022-10-06 01:30:00                  9807.906                  8516.007   \n",
       "2022-10-06 02:00:00                  9782.642                  8509.850   \n",
       "2022-10-06 02:30:00                  9755.195                  8503.090   \n",
       "2022-10-06 03:00:00                  9725.836                  8494.012   \n",
       "2022-10-06 03:30:00                  9698.191                  8489.970   \n",
       "2022-10-06 04:00:00                  9660.177                  8478.136   \n",
       "\n",
       "                     SA1_AVAILABLEGENERATION  TAS1_AVAILABLEGENERATION  \\\n",
       "DATETIME                                                                 \n",
       "2022-10-05 12:30:00                 1934.369                  2240.866   \n",
       "2022-10-05 13:00:00                 2014.529                  2235.231   \n",
       "2022-10-05 13:30:00                 2063.701                  2205.494   \n",
       "2022-10-05 14:00:00                 2091.244                  2203.250   \n",
       "2022-10-05 14:30:00                 2121.812                  2226.560   \n",
       "2022-10-05 15:00:00                 2148.397                  2228.309   \n",
       "2022-10-05 15:30:00                 2353.836                  2348.513   \n",
       "2022-10-05 16:00:00                 2426.478                  2367.113   \n",
       "2022-10-05 16:30:00                 2433.195                  2431.000   \n",
       "2022-10-05 17:00:00                 2450.111                  2435.960   \n",
       "2022-10-05 17:30:00                 2428.511                  2445.778   \n",
       "2022-10-05 18:00:00                 2355.004                  2451.627   \n",
       "2022-10-05 18:30:00                 2248.055                  2457.496   \n",
       "2022-10-05 19:00:00                 2190.302                  2468.959   \n",
       "2022-10-05 19:30:00                 2200.918                  2471.585   \n",
       "2022-10-05 20:00:00                 2195.339                  2474.750   \n",
       "2022-10-05 20:30:00                 2188.362                  2477.720   \n",
       "2022-10-05 21:00:00                 2182.931                  2479.754   \n",
       "2022-10-05 21:30:00                 2180.053                  2481.666   \n",
       "2022-10-05 22:00:00                 2177.088                  2455.354   \n",
       "2022-10-05 22:30:00                 2151.334                  2459.706   \n",
       "2022-10-05 23:00:00                 2133.424                  2462.766   \n",
       "2022-10-05 23:30:00                 2109.869                  2466.669   \n",
       "2022-10-06 00:00:00                 2089.799                  2470.536   \n",
       "2022-10-06 00:30:00                 2076.134                  2474.937   \n",
       "2022-10-06 01:00:00                 2070.380                  2477.533   \n",
       "2022-10-06 01:30:00                 2067.027                  2482.634   \n",
       "2022-10-06 02:00:00                 2065.007                  2488.404   \n",
       "2022-10-06 02:30:00                 2067.841                  2494.909   \n",
       "2022-10-06 03:00:00                 2066.686                  2500.336   \n",
       "2022-10-06 03:30:00                 2072.697                  2505.865   \n",
       "2022-10-06 04:00:00                 2077.988                  2512.819   \n",
       "\n",
       "                     VIC1_AVAILABLEGENERATION  NSW1_TOTALDEMAND  \\\n",
       "DATETIME                                                          \n",
       "2022-10-05 12:30:00                  9076.913          8130.350   \n",
       "2022-10-05 13:00:00                  8774.439          8102.040   \n",
       "2022-10-05 13:30:00                  8940.591          8119.820   \n",
       "2022-10-05 14:00:00                  8956.163          8158.600   \n",
       "2022-10-05 14:30:00                  8969.685          8195.880   \n",
       "2022-10-05 15:00:00                  9276.916          8281.450   \n",
       "2022-10-05 15:30:00                  9406.074          8403.700   \n",
       "2022-10-05 16:00:00                  9445.230          8559.040   \n",
       "2022-10-05 16:30:00                  9466.678          8704.340   \n",
       "2022-10-05 17:00:00                  9487.960          8890.890   \n",
       "2022-10-05 17:30:00                  9570.562          9014.060   \n",
       "2022-10-05 18:00:00                  9578.846          9146.570   \n",
       "2022-10-05 18:30:00                  9546.963          9184.820   \n",
       "2022-10-05 19:00:00                  9517.895          9110.350   \n",
       "2022-10-05 19:30:00                  9521.605          8908.290   \n",
       "2022-10-05 20:00:00                  9479.764          8746.420   \n",
       "2022-10-05 20:30:00                  9607.434          8550.960   \n",
       "2022-10-05 21:00:00                  9599.540          8284.340   \n",
       "2022-10-05 21:30:00                  9741.893          8117.000   \n",
       "2022-10-05 22:00:00                  9871.805          7944.400   \n",
       "2022-10-05 22:30:00                 10009.565          7857.520   \n",
       "2022-10-05 23:00:00                 10129.879          7697.190   \n",
       "2022-10-05 23:30:00                 10116.282          7556.560   \n",
       "2022-10-06 00:00:00                 10101.510          7471.640   \n",
       "2022-10-06 00:30:00                 10070.088          7327.160   \n",
       "2022-10-06 01:00:00                 10063.533          7165.040   \n",
       "2022-10-06 01:30:00                 10008.691          6917.770   \n",
       "2022-10-06 02:00:00                  9960.477          6679.210   \n",
       "2022-10-06 02:30:00                  9922.643          6461.490   \n",
       "2022-10-06 03:00:00                  9883.984          6310.270   \n",
       "2022-10-06 03:30:00                  9834.786          6272.070   \n",
       "2022-10-06 04:00:00                  9711.467          6303.360   \n",
       "\n",
       "                     QLD1_TOTALDEMAND  SA1_TOTALDEMAND  TAS1_TOTALDEMAND  \\\n",
       "DATETIME                                                                   \n",
       "2022-10-05 12:30:00          5009.350         1166.470          1104.000   \n",
       "2022-10-05 13:00:00          5065.500         1133.430          1077.000   \n",
       "2022-10-05 13:30:00          5215.050         1063.250          1046.000   \n",
       "2022-10-05 14:00:00          5373.160         1028.240          1035.000   \n",
       "2022-10-05 14:30:00          5535.740         1005.640          1028.000   \n",
       "2022-10-05 15:00:00          5745.930         1002.610          1032.000   \n",
       "2022-10-05 15:30:00          5950.120         1031.530          1044.000   \n",
       "2022-10-05 16:00:00          6204.390         1069.000          1073.000   \n",
       "2022-10-05 16:30:00          6436.840         1140.100          1103.000   \n",
       "2022-10-05 17:00:00          6690.900         1234.040          1146.000   \n",
       "2022-10-05 17:30:00          6863.580         1344.370          1184.000   \n",
       "2022-10-05 18:00:00          6993.540         1441.320          1208.000   \n",
       "2022-10-05 18:30:00          7080.900         1529.980          1230.000   \n",
       "2022-10-05 19:00:00          7096.910         1587.120          1243.000   \n",
       "2022-10-05 19:30:00          6963.930         1619.130          1235.000   \n",
       "2022-10-05 20:00:00          6913.010         1608.020          1220.000   \n",
       "2022-10-05 20:30:00          6894.280         1556.730          1203.000   \n",
       "2022-10-05 21:00:00          6764.630         1518.810          1173.000   \n",
       "2022-10-05 21:30:00          6573.060         1469.660          1137.000   \n",
       "2022-10-05 22:00:00          6384.420         1423.070          1100.000   \n",
       "2022-10-05 22:30:00          6172.690         1377.810          1061.000   \n",
       "2022-10-05 23:00:00          6016.290         1337.350          1037.000   \n",
       "2022-10-05 23:30:00          5902.130         1320.450          1016.000   \n",
       "2022-10-06 00:00:00          5742.510         1415.340          1004.000   \n",
       "2022-10-06 00:30:00          5531.570         1394.160           999.000   \n",
       "2022-10-06 01:00:00          5397.170         1396.280           998.000   \n",
       "2022-10-06 01:30:00          5301.420         1353.410           996.000   \n",
       "2022-10-06 02:00:00          5224.390         1304.560           997.000   \n",
       "2022-10-06 02:30:00          5169.350         1259.640           992.000   \n",
       "2022-10-06 03:00:00          5144.250         1230.640          1006.000   \n",
       "2022-10-06 03:30:00          5140.160         1207.260          1016.000   \n",
       "2022-10-06 04:00:00          5161.190         1196.570          1029.000   \n",
       "\n",
       "                     VIC1_TOTALDEMAND  NSW1_GEN_Solar  QLD1_GEN_Solar  \\\n",
       "DATETIME                                                                \n",
       "2022-10-05 12:30:00          5456.200         496.022        1321.744   \n",
       "2022-10-05 13:00:00          5401.020         447.007        1291.293   \n",
       "2022-10-05 13:30:00          5379.560         439.765        1208.926   \n",
       "2022-10-05 14:00:00          5372.330         417.931        1081.243   \n",
       "2022-10-05 14:30:00          5365.550         384.167         941.403   \n",
       "2022-10-05 15:00:00          5411.890         337.472         805.239   \n",
       "2022-10-05 15:30:00          5496.090         291.108         565.523   \n",
       "2022-10-05 16:00:00          5587.400         239.314         450.004   \n",
       "2022-10-05 16:30:00          5715.050         171.940         319.109   \n",
       "2022-10-05 17:00:00          5855.500         117.174         179.303   \n",
       "2022-10-05 17:30:00          5917.010          72.320          66.381   \n",
       "2022-10-05 18:00:00          5909.840          24.681           8.794   \n",
       "2022-10-05 18:30:00          5880.340           2.927           0.032   \n",
       "2022-10-05 19:00:00          5882.850           0.128           0.000   \n",
       "2022-10-05 19:30:00          5825.230           0.000           0.000   \n",
       "2022-10-05 20:00:00          5800.510           0.000           0.000   \n",
       "2022-10-05 20:30:00          5606.780           0.000           0.000   \n",
       "2022-10-05 21:00:00          5378.170           0.000           0.000   \n",
       "2022-10-05 21:30:00          5120.510           0.000           0.000   \n",
       "2022-10-05 22:00:00          4870.930           0.000           0.000   \n",
       "2022-10-05 22:30:00          4654.870           0.000           0.000   \n",
       "2022-10-05 23:00:00          4487.750           0.000           0.000   \n",
       "2022-10-05 23:30:00          4519.210           0.000           0.000   \n",
       "2022-10-06 00:00:00          4484.660           0.000           0.000   \n",
       "2022-10-06 00:30:00          4347.710           0.000           0.000   \n",
       "2022-10-06 01:00:00          4209.140           0.000           0.000   \n",
       "2022-10-06 01:30:00          4077.060           0.000           0.000   \n",
       "2022-10-06 02:00:00          3956.690           0.000           0.000   \n",
       "2022-10-06 02:30:00          3872.400           0.000           0.000   \n",
       "2022-10-06 03:00:00          3827.410           0.000           0.000   \n",
       "2022-10-06 03:30:00          3823.800           0.000           0.000   \n",
       "2022-10-06 04:00:00          3870.140           0.000           0.000   \n",
       "\n",
       "                     SA1_GEN_Solar  TAS1_GEN_Solar  VIC1_GEN_Solar  \\\n",
       "DATETIME                                                             \n",
       "2022-10-05 12:30:00        220.511           0.000         137.262   \n",
       "2022-10-05 13:00:00        227.712           0.000         126.049   \n",
       "2022-10-05 13:30:00        237.183           0.000         128.198   \n",
       "2022-10-05 14:00:00        235.381           0.000         130.048   \n",
       "2022-10-05 14:30:00        225.720           0.000         124.838   \n",
       "2022-10-05 15:00:00        230.460           0.000         116.731   \n",
       "2022-10-05 15:30:00        264.814           0.000         105.547   \n",
       "2022-10-05 16:00:00        260.899           0.000          91.830   \n",
       "2022-10-05 16:30:00        251.468           0.000          75.270   \n",
       "2022-10-05 17:00:00        229.213           0.000          56.418   \n",
       "2022-10-05 17:30:00        180.502           0.000          37.950   \n",
       "2022-10-05 18:00:00        115.122           0.000          19.983   \n",
       "2022-10-05 18:30:00         39.751           0.000           2.903   \n",
       "2022-10-05 19:00:00          1.332           0.000           0.000   \n",
       "2022-10-05 19:30:00          1.009           0.000           0.000   \n",
       "2022-10-05 20:00:00          1.009           0.000           0.000   \n",
       "2022-10-05 20:30:00          1.009           0.000           0.000   \n",
       "2022-10-05 21:00:00          1.009           0.000           0.000   \n",
       "2022-10-05 21:30:00          1.009           0.000           0.000   \n",
       "2022-10-05 22:00:00          1.009           0.000           0.000   \n",
       "2022-10-05 22:30:00          1.009           0.000           0.000   \n",
       "2022-10-05 23:00:00          1.009           0.000           0.000   \n",
       "2022-10-05 23:30:00          1.009           0.000           0.000   \n",
       "2022-10-06 00:00:00          1.009           0.000           0.000   \n",
       "2022-10-06 00:30:00          1.009           0.000           0.000   \n",
       "2022-10-06 01:00:00          1.009           0.000           0.000   \n",
       "2022-10-06 01:30:00          1.009           0.000           0.000   \n",
       "2022-10-06 02:00:00          1.009           0.000           0.000   \n",
       "2022-10-06 02:30:00          1.009           0.000           0.000   \n",
       "2022-10-06 03:00:00          1.009           0.000           0.000   \n",
       "2022-10-06 03:30:00          1.009           0.000           0.000   \n",
       "2022-10-06 04:00:00          1.009           0.000           0.000   \n",
       "\n",
       "                     NSW1_GEN_Wind  QLD1_GEN_Wind  SA1_GEN_Wind  \\\n",
       "DATETIME                                                          \n",
       "2022-10-05 12:30:00       1211.028        154.643       296.858   \n",
       "2022-10-05 13:00:00       1212.362        142.115       368.817   \n",
       "2022-10-05 13:30:00       1216.382        145.189       410.518   \n",
       "2022-10-05 14:00:00       1223.474        151.305       442.863   \n",
       "2022-10-05 14:30:00       1226.035        163.021       468.092   \n",
       "2022-10-05 15:00:00       1228.472        177.376       490.937   \n",
       "2022-10-05 15:30:00       1241.875        209.696       511.022   \n",
       "2022-10-05 16:00:00       1224.711        224.617       532.579   \n",
       "2022-10-05 16:30:00       1238.281        232.816       487.727   \n",
       "2022-10-05 17:00:00       1274.637        243.083       446.898   \n",
       "2022-10-05 17:30:00       1293.328        252.840       414.009   \n",
       "2022-10-05 18:00:00       1316.791        260.493       372.882   \n",
       "2022-10-05 18:30:00       1337.424        264.325       339.304   \n",
       "2022-10-05 19:00:00       1352.309        270.549       318.970   \n",
       "2022-10-05 19:30:00       1361.760        292.031       311.909   \n",
       "2022-10-05 20:00:00       1368.762        312.284       307.330   \n",
       "2022-10-05 20:30:00       1370.685        329.259       300.353   \n",
       "2022-10-05 21:00:00       1371.736        349.542       296.922   \n",
       "2022-10-05 21:30:00       1371.590        390.647       295.044   \n",
       "2022-10-05 22:00:00       1369.981        424.847       294.079   \n",
       "2022-10-05 22:30:00       1372.019        428.081       268.325   \n",
       "2022-10-05 23:00:00       1370.465        425.603       245.415   \n",
       "2022-10-05 23:30:00       1349.220        416.761       220.860   \n",
       "2022-10-06 00:00:00       1339.119        399.805       199.790   \n",
       "2022-10-06 00:30:00       1308.474        388.013       186.125   \n",
       "2022-10-06 01:00:00       1283.444        377.932       176.371   \n",
       "2022-10-06 01:30:00       1251.906        368.007       173.018   \n",
       "2022-10-06 02:00:00       1226.642        359.850       170.998   \n",
       "2022-10-06 02:30:00       1199.195        351.090       169.832   \n",
       "2022-10-06 03:00:00       1169.836        342.012       170.677   \n",
       "2022-10-06 03:30:00       1137.191        335.970       175.688   \n",
       "2022-10-06 04:00:00       1099.177        323.136       180.979   \n",
       "\n",
       "                     TAS1_GEN_Wind  VIC1_GEN_Wind  \n",
       "DATETIME                                           \n",
       "2022-10-05 12:30:00        211.866       2116.651  \n",
       "2022-10-05 13:00:00        206.231       2107.390  \n",
       "2022-10-05 13:30:00        204.494       2115.393  \n",
       "2022-10-05 14:00:00        202.250       2129.115  \n",
       "2022-10-05 14:30:00        203.560       2148.847  \n",
       "2022-10-05 15:00:00        205.309       2187.185  \n",
       "2022-10-05 15:30:00        207.513       2267.527  \n",
       "2022-10-05 16:00:00        211.113       2313.400  \n",
       "2022-10-05 16:30:00        217.000       2334.408  \n",
       "2022-10-05 17:00:00        221.960       2373.542  \n",
       "2022-10-05 17:30:00        231.778       2394.612  \n",
       "2022-10-05 18:00:00        237.627       2415.863  \n",
       "2022-10-05 18:30:00        243.496       2435.060  \n",
       "2022-10-05 19:00:00        254.959       2450.895  \n",
       "2022-10-05 19:30:00        257.585       2459.605  \n",
       "2022-10-05 20:00:00        260.750       2454.764  \n",
       "2022-10-05 20:30:00        263.720       2451.434  \n",
       "2022-10-05 21:00:00        265.754       2455.540  \n",
       "2022-10-05 21:30:00        267.666       2454.893  \n",
       "2022-10-05 22:00:00        269.354       2452.805  \n",
       "2022-10-05 22:30:00        273.706       2444.565  \n",
       "2022-10-05 23:00:00        276.766       2433.879  \n",
       "2022-10-05 23:30:00        280.669       2419.282  \n",
       "2022-10-06 00:00:00        284.536       2402.510  \n",
       "2022-10-06 00:30:00        288.937       2371.088  \n",
       "2022-10-06 01:00:00        291.533       2350.533  \n",
       "2022-10-06 01:30:00        296.634       2300.691  \n",
       "2022-10-06 02:00:00        302.404       2251.477  \n",
       "2022-10-06 02:30:00        308.909       2208.643  \n",
       "2022-10-06 03:00:00        314.336       2159.984  \n",
       "2022-10-06 03:30:00        319.865       2099.786  \n",
       "2022-10-06 04:00:00        326.819       2038.467  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9107dd3b-03fa-4ae9-8635-9f5cd8a23378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded csv: ../data/download_cache/PUBLIC_PREDISPATCHIS_202210051230_20221005120151.CSV\n",
      "Already downloaded csv: ../data/download_cache/PUBLIC_STPASA_202210051200_0000000372182536.CSV\n",
      "DATETIME\n",
      "2022-10-05 18:00:00   11032.221\n",
      "2022-10-06 00:00:00   10989.762\n",
      "2022-10-06 06:00:00    9864.474\n",
      "2022-10-06 12:00:00    9059.000\n",
      "2022-10-06 18:00:00    9240.000\n",
      "2022-10-07 00:00:00    9219.000\n",
      "2022-10-07 06:00:00    9662.000\n",
      "2022-10-07 12:00:00   10527.000\n",
      "2022-10-07 18:00:00   10519.000\n",
      "2022-10-08 00:00:00   10541.000\n",
      "2022-10-08 06:00:00   10542.000\n",
      "2022-10-08 12:00:00   11230.000\n",
      "2022-10-08 18:00:00   11214.000\n",
      "2022-10-09 00:00:00   11226.000\n",
      "2022-10-09 06:00:00   10572.000\n",
      "2022-10-09 12:00:00   11234.000\n",
      "2022-10-09 18:00:00   11218.000\n",
      "2022-10-10 00:00:00   11230.000\n",
      "2022-10-10 06:00:00   10572.000\n",
      "2022-10-10 12:00:00   11200.000\n",
      "2022-10-10 18:00:00   11192.000\n",
      "2022-10-11 00:00:00   11205.000\n",
      "2022-10-11 06:00:00   10555.000\n",
      "2022-10-11 12:00:00   11209.000\n",
      "2022-10-11 18:00:00   11039.000\n",
      "2022-10-12 00:00:00   11054.000\n",
      "2022-10-12 06:00:00   10408.000\n",
      "Freq: 6H, Name: NSW1_AVAILABLEGENERATION, dtype: float64\n",
      "DATETIME\n",
      "2022-10-05 18:00:00   11032.221\n",
      "2022-10-06 00:00:00   10989.762\n",
      "2022-10-06 06:00:00    9864.474\n",
      "2022-10-06 12:00:00    9059.000\n",
      "2022-10-06 18:00:00    9240.000\n",
      "2022-10-07 00:00:00    9219.000\n",
      "2022-10-07 06:00:00    9662.000\n",
      "2022-10-07 12:00:00   10527.000\n",
      "2022-10-07 18:00:00   10519.000\n",
      "2022-10-08 00:00:00   10541.000\n",
      "2022-10-08 06:00:00   10542.000\n",
      "2022-10-08 12:00:00   11230.000\n",
      "2022-10-08 18:00:00   11214.000\n",
      "2022-10-09 00:00:00   11226.000\n",
      "2022-10-09 06:00:00   10572.000\n",
      "2022-10-09 12:00:00   11234.000\n",
      "2022-10-09 18:00:00   11218.000\n",
      "2022-10-10 00:00:00   11230.000\n",
      "2022-10-10 06:00:00   10572.000\n",
      "2022-10-10 12:00:00   11200.000\n",
      "2022-10-10 18:00:00   11192.000\n",
      "2022-10-11 00:00:00   11205.000\n",
      "2022-10-11 06:00:00   10555.000\n",
      "2022-10-11 12:00:00   11209.000\n",
      "2022-10-11 18:00:00   11039.000\n",
      "2022-10-12 00:00:00   11054.000\n",
      "2022-10-12 06:00:00   10408.000\n",
      "2022-10-11 12:00:00   11209.000\n",
      "2022-10-11 18:00:00   11039.000\n",
      "2022-10-12 00:00:00   11054.000\n",
      "2022-10-12 06:00:00   10408.000\n",
      "2022-10-11 12:00:00   11209.000\n",
      "2022-10-11 18:00:00   11039.000\n",
      "2022-10-12 00:00:00   11054.000\n",
      "2022-10-12 06:00:00   10408.000\n",
      "Name: NSW1_AVAILABLEGENERATION, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_price_gen_forecasts():\n",
    "    \"\"\"Get features for forecasts of Price & Gen by Region.\n",
    "\n",
    "    Combination pre-dispatch (for the next day-or-so) and STPASA (which starts at 4.30am on day after next trading day)\n",
    "    Outputs dict of features:\n",
    "        'RG_AVAILABLEGENERATION_Tp6', 'RG_AVAILABLEGENERATION_Tp12'...'RG_AVAILABLEGENERATION_Tp168',\n",
    "        'RG_TOTALDEMAND_Tp6', 'RG_TOTALDEMAND_Tp12'... 'RG_TOTALDEMAND_Tp168',\n",
    "        'RG_GEN_Solar_Tp6', 'RG_GEN_Solar_Tp12', ... 'RG_GEN_Solar_Tp168',\n",
    "        'RG_GEN_Wind_Tp6', 'RG_GEN_Wind_Tp12', ... 'RG_GEN_Wind_Tp168',\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    ### First, we get predispatch data, which covers until the end of the next trading day (4am)\n",
    "    filename = get_latest_file_from_folder('PredispatchIS_Reports')\n",
    "    predis = pd.read_csv(get_subtable_from_file(filename, 'PREDISPATCH,REGION_SOLUTION'),\n",
    "                        usecols=['REGIONID', 'DATETIME', 'AVAILABLEGENERATION', 'TOTALDEMAND', \n",
    "                                'NETINTERCHANGE', 'SS_SOLAR_UIGF', 'SS_WIND_UIGF'],\n",
    "                        parse_dates=['DATETIME'],\n",
    "                        index_col='DATETIME')\n",
    "\n",
    "    # IC_NET is defined to be NETINTERCHANGE * -1. IC_NET: import is +ve generation... though ignoring IC_net for now\n",
    "    predis['NETINTERCHANGE'] = predis['NETINTERCHANGE'] * -1\n",
    "    predis = predis.rename(columns={\n",
    "        'NETINTERCHANGE': 'IC_NET',\n",
    "        'SS_SOLAR_UIGF': 'GEN_Solar', \n",
    "        'SS_WIND_UIGF': 'GEN_Wind', \n",
    "    })\n",
    "    predis = predis.pivot(columns='REGIONID', values=['AVAILABLEGENERATION', 'TOTALDEMAND', 'GEN_Solar', 'GEN_Wind'])\n",
    "    predis.columns = [f'{region}_{col}' for col, region in predis.columns]\n",
    "\n",
    "\n",
    "    ### Second, we get ST PASA data, which covers the remainder of the 7 days\n",
    "    filename = get_latest_file_from_folder('Short_Term_PASA_Reports')\n",
    "    stpasa = pd.read_csv(get_subtable_from_file(filename, 'STPASA,REGIONSOLUTION'),\n",
    "                        usecols=['REGIONID', 'INTERVAL_DATETIME', 'AGGREGATECAPACITYAVAILABLE', 'DEMAND50', \n",
    "                                'SS_SOLAR_UIGF', 'SS_WIND_UIGF'],\n",
    "                        parse_dates=['INTERVAL_DATETIME'],\n",
    "                    )\n",
    "    stpasa = stpasa.rename(columns={\n",
    "        'INTERVAL_DATETIME': 'DATETIME',\n",
    "        'DEMAND50': 'TOTALDEMAND',\n",
    "        'AGGREGATECAPACITYAVAILABLE': 'AVAILABLEGENERATION',\n",
    "        'SS_SOLAR_UIGF': 'GEN_Solar', \n",
    "        'SS_WIND_UIGF': 'GEN_Wind', \n",
    "    })\n",
    "    stpasa = stpasa.drop_duplicates(['REGIONID', 'DATETIME'], keep='first')  # there are multiple 'runs' in here, eg \"LOR\" and \"OUTAGE_LRC\". \"LOR\" first\n",
    "    stpasa = stpasa.set_index('DATETIME')\n",
    "    stpasa = stpasa.pivot(columns='REGIONID', values=['AVAILABLEGENERATION', 'TOTALDEMAND', 'GEN_Solar', 'GEN_Wind'])\n",
    "    stpasa.columns = [f'{region}_{col}' for col, region in stpasa.columns]\n",
    "\n",
    "    gen = pd.concat([predis, stpasa])\n",
    "\n",
    "    # like done in dataset generator, take the max over each N=6hr increment.\n",
    "    gen = gen.resample('6H', label='right', closed='right').max()\n",
    "    print(gen.NSW1_AVAILABLEGENERATION)\n",
    "\n",
    "    # we don't always have enough data to go right out to 7 days. Worst case is just before the new PASA/predis are released at 1pm NEM time\n",
    "    # extend the data we do have by copying the final 24h two more times to extend by 48h, which is more than enough (36h would also be enough)\n",
    "    last_24h = gen[-4:].copy()\n",
    "    gen = pd.concat([gen, last_24h, last_24h])\n",
    "    print(gen.NSW1_AVAILABLEGENERATION)\n",
    "\n",
    "\n",
    "    for i, lag in enumerate(list(range(6, 168+6, 6))):\n",
    "        for col in gen.columns:\n",
    "            output[f'{col}_Tp{lag}'] = gen.iloc[i][col]\n",
    "    return output\n",
    "features = features | get_price_gen_forecasts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d885d27-5661-4983-8045-ea12bff957de",
   "metadata": {},
   "source": [
    "## Availability by fuel type\n",
    "- the most up to date availabilty by feul source (up-to-minute data is secret, not available)\n",
    "- also uses the \"daily report\", the most recent one, which comes out at 4am each day\n",
    "- using instantaneous data from 24 hours ago as best estimate for availablity now. Alternative was to use the most recent, which is 4am today. Line ball call, went for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f486e-08fd-493a-a382-69b8b8c5fe3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_availability_by_fuel(duids):\n",
    "    \"\"\"Get availability features by fuel type.\n",
    "    \n",
    "    The most up to date availabilty by feul source (up-to-minute data is secret, not available)\n",
    "    Also uses the \"daily report\", the most recent one, which comes out at 4am each day\n",
    "    Using instantaneous data from 24 hours ago as best estimate for availablity now. Alternative\n",
    "    was to use the most recent, which is 4am today. Line ball call, went for this. \n",
    "    \"\"\"\n",
    "    filename = get_latest_file_from_folder('Daily_Reports') \n",
    "    df = pd.read_csv(get_subtable_from_file(filename, ',DUNIT,,3'),\n",
    "                     usecols=['SETTLEMENTDATE', 'DUID', 'AVAILABILITY', ],\n",
    "                     parse_dates=['SETTLEMENTDATE'],\n",
    "                     index_col='SETTLEMENTDATE'\n",
    "                    )\n",
    "    df = df.join(duids, on='DUID')\n",
    "\n",
    "    # drop any loads, only want generators\n",
    "    df = df[df.GENSETTYPE == 'GENERATOR']\n",
    "\n",
    "    # rows that have same time of day as now (date ignored). \n",
    "    df = df[df.index.time == pd.Timestamp.now().round('5min').time()]\n",
    "    df = df.groupby(['REGIONID', 'CO2E_ENERGY_SOURCE']).agg({\n",
    "        'AVAILABILITY': np.sum,\n",
    "    }).reset_index()\n",
    "\n",
    "    # feature names are eg VIC1_AVAILABILITY_Coal\n",
    "    df['name'] = df['REGIONID'] + '_AVAILABILITY_' + df['CO2E_ENERGY_SOURCE']\n",
    "    df = df.set_index('name')\n",
    "\n",
    "    output = {}\n",
    "    for region in REGIONIDS:\n",
    "        for fuel in ['Battery Storage', 'Coal', 'Gas', 'Hydro', 'Solar', 'Wind']:\n",
    "            col = f'{region}_AVAILABILITY_{fuel}'\n",
    "            output[col] = df.at[col, 'AVAILABILITY'] if col in df.index else 0\n",
    "    return output\n",
    "features = features | get_availability_by_fuel(duids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63251348-fafa-42a6-9cba-ceaa15d9c034",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generation by fuel type\n",
    "Table `DISPATCHSCADA`, which gets all generation of every plant (DUID). Not that availability isn't provided because it's secret till next day. We don't have access to the table used in dataset generator, `DISPATCHLOAD`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ba34e-13fd-47a1-b97a-8306d4c3cc11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_generation_by_fuel(duids):\n",
    "    \"\"\"Gets generaetion features broken down by fuel for the current time\n",
    "    \n",
    "    Uses table  `DISPATCHSCADA` to get generation for every plant (DUID).\n",
    "    Note that availability isn't provided because it's secret till next day. \n",
    "    We don't have access to the table used in dataset generator, DISPATCHLOAD.\n",
    "    \"\"\"\n",
    "    filename = get_latest_file_from_folder('Dispatch_SCADA')\n",
    "    df = pd.read_csv(filename, \n",
    "                     skiprows=[0, -1], # skip first and last rows\n",
    "                     usecols=['DUID', 'SCADAVALUE'],\n",
    "                     index_col='DUID'\n",
    "                    ).join(duids)\n",
    "\n",
    "    # drop any loads, only want generators\n",
    "    df = df[df.GENSETTYPE == 'GENERATOR']\n",
    "\n",
    "    df = df.groupby(['REGIONID', 'CO2E_ENERGY_SOURCE']).agg({\n",
    "        'SCADAVALUE': np.sum,\n",
    "        # 'AVAILABILITY': np.sum,\n",
    "    }).reset_index()\n",
    "\n",
    "    # no negatives \n",
    "    df['SCADAVALUE'] = df['SCADAVALUE'].clip(lower=0)\n",
    "\n",
    "    # feature names are eg VIC1_GEN_Coal\n",
    "    df['name'] = df['REGIONID'] + '_GEN_' + df['CO2E_ENERGY_SOURCE']\n",
    "    df = df.set_index('name')\n",
    "\n",
    "    output = {}\n",
    "    for region in REGIONIDS:\n",
    "        for fuel in ['Battery Storage', 'Coal', 'Gas', 'Hydro', 'Solar', 'Wind']:\n",
    "            col = f'{region}_GEN_{fuel}'\n",
    "            output[col] = df.at[col, 'SCADAVALUE'] if col in df.index else 0\n",
    "    return output\n",
    "features = features | get_generation_by_fuel(duids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6442611-29fc-48a1-9ed7-3e22fc7a4efb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rooftop PV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3238ae8-4e4a-43fb-bfb5-93ea6dc65914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rooftop_pv():\n",
    "    \"\"\"Gets features for current and forecast rooftop pv output.\"\"\"\n",
    "    # Current values\n",
    "    filename = get_latest_file_from_folder('ROOFTOP_PV/ACTUAL')\n",
    "    df = pd.read_csv(filename, \n",
    "                     skiprows=1,\n",
    "                     skipfooter=1,\n",
    "                     engine='python',\n",
    "                     usecols=['REGIONID', 'POWER'],\n",
    "                     index_col='REGIONID')\n",
    "    current_rooftop = {}\n",
    "    for region in REGIONIDS:\n",
    "        current_rooftop[f'{region}_GEN_Rooftop'] = df.at[region, 'POWER']\n",
    "\n",
    "    # Rooftop PV forecasts\n",
    "    filename = get_latest_file_from_folder('ROOFTOP_PV/FORECAST')\n",
    "    df = pd.read_csv(filename, \n",
    "                     skiprows=1,\n",
    "                     skipfooter=1,\n",
    "                     engine='python',\n",
    "                     usecols=['INTERVAL_DATETIME', 'REGIONID', 'POWERPOE50'],\n",
    "                     index_col='INTERVAL_DATETIME')\n",
    "    df = df.pivot(columns='REGIONID', values='POWERPOE50')\n",
    "\n",
    "    # like done in dataset generator, take the max over each 6hr increment.\n",
    "    df = df.rolling(2 * 6).max()\n",
    "    df = df[11::12]  # take every 12th line, starting from the 11th, which is the end of the first block of 6hrs\n",
    "\n",
    "    len(['RG_GEN_Rooftop_Tp6', 'RG_GEN_Rooftop_Tp12', 'RG_GEN_Rooftop_Tp18', 'RG_GEN_Rooftop_Tp24', 'RG_GEN_Rooftop_Tp30', 'RG_GEN_Rooftop_Tp36', 'RG_GEN_Rooftop_Tp42', 'RG_GEN_Rooftop_Tp48', 'RG_GEN_Rooftop_Tp54', 'RG_GEN_Rooftop_Tp60', 'RG_GEN_Rooftop_Tp66', 'RG_GEN_Rooftop_Tp72', 'RG_GEN_Rooftop_Tp78', 'RG_GEN_Rooftop_Tp84', 'RG_GEN_Rooftop_Tp90', 'RG_GEN_Rooftop_Tp96', 'RG_GEN_Rooftop_Tp102', 'RG_GEN_Rooftop_Tp108', 'RG_GEN_Rooftop_Tp114', 'RG_GEN_Rooftop_Tp120', 'RG_GEN_Rooftop_Tp126', 'RG_GEN_Rooftop_Tp132', 'RG_GEN_Rooftop_Tp138', 'RG_GEN_Rooftop_Tp144', 'RG_GEN_Rooftop_Tp150', 'RG_GEN_Rooftop_Tp156', 'RG_GEN_Rooftop_Tp162', 'RG_GEN_Rooftop_Tp168'])\n",
    "\n",
    "    forecast_rooftop = {}\n",
    "    for region in REGIONIDS:\n",
    "        for i, lag in enumerate(range(6, 168+6, 6)):\n",
    "            forecast_rooftop[f'{region}_GEN_Rooftop_Tp{lag}'] = df.iloc[i][region]\n",
    "\n",
    "    return current_rooftop | forecast_rooftop \n",
    "\n",
    "features = features | get_rooftop_pv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7534a83a-2487-44c3-b5ff-9ea289e37bac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Interconnector forecasts... TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66317d07-dc3d-41a7-8ba1-ac3aacac2376",
   "metadata": {},
   "source": [
    "not sure this is the right data either ??? seems to only be at one of these types of model scenario:'RELIABILITY_LRC', 'OUTAGE_LRC', 'LOR'. [Link to explain?](https://aemo.com.au/-/media/archive/files/electricity/consultations/2015/attachment-1-rsig.pdf) . so probably not a reliable indicator of IC_NET in future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb94ae-f645-4fcd-8a48-6bc426a59905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filename = get_latest_file_from_folder('Short_Term_PASA_Reports')\n",
    "# df = pd.read_csv(get_subtable_from_file(filename, 'STPASA,INTERCONNECTORSOLN'),\n",
    "#                  # usecols=['REGIONID', 'INTERVAL_DATETIME', 'AGGREGATECAPACITYAVAILABLE', 'DEMAND50', \n",
    "#                  #          'SS_SOLAR_UIGF', 'SS_WIND_UIGF'],\n",
    "#                  # parse_dates=['INTERVAL_DATETIME'],\n",
    "#                  # index_col='INTERVAL_DATETIME',\n",
    "#                 )\n",
    "# df.RUNTYPE.unique()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dfb88e-ecc8-4943-9071-3ec9184caf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['RUNTYPE']=='RELIABILITY_LRC'].set_index('INTERVAL_DATETIME').pivot(columns=['INTERCONNECTORID'], values=['CALCULATEDEXPORTLIMIT','CALCULATEDIMPORTLIMIT']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef11b3c-035b-4083-acee-a95a8968e50f",
   "metadata": {},
   "source": [
    "### alternative source... but no... werid data :(\n",
    "NET_INTERCHANGE == IC_NET * -1\n",
    "\n",
    "\n",
    "TODO: this seems to suck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ecdb00-6f77-4041-b969-7bd5df146c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = download_and_unzip_file('http://www.nemweb.com.au/REPORTS/CURRENT/SEVENDAYOUTLOOK_FULL/PUBLIC_SEVENDAYOUTLOOK_FULL_20220810231348_0000000368596516.zip')\n",
    "# df = pd.read_csv(filename, \n",
    "#                  skiprows=1,\n",
    "#                  skipfooter=1, engine='python', # need engine=python to use skipfooter\n",
    "#                  parse_dates=['INTERVAL_DATETIME'],\n",
    "#                  index_col='INTERVAL_DATETIME', \n",
    "#                  usecols=['INTERVAL_DATETIME', 'REGIONID', 'NET_INTERCHANGE']\n",
    "#                 )\n",
    "\n",
    "# # IC_NET is defined to be NETINTERCHANGE * -1. IC_NET: import is +ve generation.\n",
    "# df['NET_INTERCHANGE'] = df['NET_INTERCHANGE'] * -1\n",
    "# df = df.rename(columns={'NET_INTERCHANGE': 'IC_NET'})\n",
    "# df = df.pivot(columns='REGIONID', values='IC_NET')\n",
    "\n",
    "# print_item(df)\n",
    "# df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8251a923-5c75-4e1c-bb7a-f2c1b6a88171",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Greenness mean of last 30 days\n",
    "Inputs:\n",
    "- Again, use the \"daily report\" (also used by 30d price lags): (all 30 days available from one folder)\n",
    "  - gen by fuel: This time we want a different subtable `DUNIT`, which has all the data by DUID. \n",
    "  - net interconnector flow: `DREGION` subtable\n",
    "- Rooftop PV Actual (not forecast) data - in its own separate dataset (only 14 (?) days available from current folder, go to archive for the remanider)\n",
    "\n",
    "First, rooftop PV:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f26cc-31b8-4b41-82c7-25a23ad10fce",
   "metadata": {},
   "source": [
    "### Get last 30d of rooftop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371679df-f467-4621-8302-c741ea0d77c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_row_from_pv_file(csv_file):\n",
    "    df = pd.read_csv(csv_file,\n",
    "                     skiprows=1,\n",
    "                     skipfooter=1,\n",
    "                     engine='python',\n",
    "                     usecols=['INTERVAL_DATETIME', 'REGIONID', 'POWER'],\n",
    "                     parse_dates=['INTERVAL_DATETIME'],\n",
    "                     index_col='REGIONID')\n",
    "    row = {f'{region}_GEN_Rooftop': df.at[region, 'POWER'] for region in REGIONIDS}\n",
    "    row['SETTLEMENTDATE'] = df.at['VIC1', 'INTERVAL_DATETIME']\n",
    "    return row\n",
    "\n",
    "\n",
    "def get_recent_weeks_of_pv_data():\n",
    "    # download the 4 most recent weeks of data from the archive folder and extract into a dataframe\n",
    "    rows = []\n",
    "    PV_CACHE_FOLDER = DATA_FOLDER / 'download_cache/RooftopPVActual/'\n",
    "    if not os.path.exists(PV_CACHE_FOLDER):\n",
    "        os.makedirs(PV_CACHE_FOLDER)\n",
    "    for nth_most_recent in [-4, -3, -2, -1]:\n",
    "\n",
    "        for retries in range(5):\n",
    "            response = requests.get('http://nemweb.com.au/Reports/Archive/ROOFTOP_PV/ACTUAL/')\n",
    "            if (len(response.text) > 2000): # predipatch table is 3100 or so\n",
    "                break\n",
    "        soup = BeautifulSoup(response.text, features='lxml')\n",
    "        latest = soup.find_all('a')[nth_most_recent]['href']\n",
    "        zip_url = f'http://nemweb.com.au{latest}'\n",
    "        filename = zip_url.split('/')[-1]\n",
    "        filepath = PV_CACHE_FOLDER / filename\n",
    "        print(f\"Downloading {zip_url}\")\n",
    "        # extract the .zip contents (which is more .zip files, extract and parse them too)\n",
    "        response = requests.get(zip_url)\n",
    "        # with open(DATA_FOLDER / 'download_cache/PUBLIC_ROOFTOP_PV_ACTUAL_SATELLITE_20220728.zip', 'rb') as f:\n",
    "        #     temp = f.read()\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as outer_zip:\n",
    "        # with zipfile.ZipFile(io.BytesIO(temp)) as outer_zip:\n",
    "            # outer_zip contains a bunch more zip files (only). Read these into memory too. \n",
    "            for inner_zip_name in outer_zip.namelist():\n",
    "                with zipfile.ZipFile(outer_zip.open(inner_zip_name)) as inner_zip:\n",
    "                    # inner zip files contain only one file - blah.csv. Read this into memory. \n",
    "                    with inner_zip.open(inner_zip.namelist()[0]) as csv_file:\n",
    "                        rows.append(extract_row_from_pv_file(csv_file))\n",
    "\n",
    "    df = pd.DataFrame(rows).set_index('SETTLEMENTDATE')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783438b0-dd20-4578-a4c5-323d25f617ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a whole day of PV actual data\n",
    "# This data is midnight-to-midnight, unlike the data we're joinign to which is 4am-4am, but we can assume there's 0 PV between midnight and 4am!!!  :D\n",
    "# downloads all the files (one per half-hour) for the given day \n",
    "def get_PV_actual_for_one_day(target_date):\n",
    "    \n",
    "    # There are both \"satellite\" and \"measurement\" files. Two measurements of same thing. Assume we want satellite. \n",
    "    match_str = f\"SATELLITE_{target_date.strftime('%Y%m%d')}\"  # eg 'SATELLITE_20220813'\n",
    "    filenames = get_files_from_folder('ROOFTOP_PV/ACTUAL', match_str)    \n",
    "    \n",
    "    # one row (file) per half-hour timestamp\n",
    "    rows = []\n",
    "    for filename in filenames:\n",
    "        df = pd.read_csv(filename, skiprows=1, parse_dates=['INTERVAL_DATETIME'])\n",
    "        df = df.set_index('REGIONID')\n",
    "        row = {f\"{region}_GEN_Rooftop\": df.at[region,'POWER'] for region in REGIONIDS}\n",
    "        row['SETTLEMENTDATE'] = df.at['VIC1', 'INTERVAL_DATETIME']\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.set_index('SETTLEMENTDATE')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c230ed-9dc1-4de1-beb9-f6b432bceec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last 30d of rooftop pvdata, \n",
    "# starts by either loading from disk if available or otherwise grabs week-large chunks from the nem archive\n",
    "# then tops up either with most recent data\n",
    "def get_last_30d_of_pv_data():\n",
    "    \n",
    "    if os.path.exists(DATA_FOLDER / 'greenness_rooftop_30d_cache.csv'):\n",
    "        df = pd.read_csv(DATA_FOLDER / 'greenness_rooftop_30d_cache.csv',\n",
    "                         parse_dates=['SETTLEMENTDATE'],\n",
    "                         index_col='SETTLEMENTDATE')\n",
    "    else:\n",
    "        print(\"No Cache; running get_recent_weeks_of_pv_data()\")\n",
    "        df = get_recent_weeks_of_pv_data()\n",
    "\n",
    "    # if the data in the cache is old for some reason, just refresh entirely.\n",
    "    if datetime.now().date() - df.index[-1].date() > timedelta(days=10):\n",
    "        print(\"Cache is old; refresh it with get_recent_weeks_of_pv_data()\")\n",
    "        df = get_recent_weeks_of_pv_data()\n",
    "    \n",
    "    # delete anything from today's date  # TODO really no point to grabbing in day sized chunks any more...\n",
    "    df = df[df.index < pd.Timestamp.now().floor('D')]\n",
    "\n",
    "    # now get any remaining recent days. If getting from NEM archive, should be . \n",
    "    # start with the first missing date:\n",
    "    d = df.index[-1].date() + timedelta(days=1)\n",
    "    days = []\n",
    "    while d <= datetime.now().date():\n",
    "        print(\"get_PV_actual_for_one_day(\" + d.strftime('%Y%m%d') + \")\")\n",
    "        days.append(get_PV_actual_for_one_day(d))\n",
    "        d = d + timedelta(days=1)\n",
    "\n",
    "    days.append(df)\n",
    "\n",
    "    greenness_rooftop = pd.concat(days).sort_index()\n",
    "    \n",
    "    #drop duplicates\n",
    "    greenness_rooftop = greenness_rooftop[~greenness_rooftop.index.duplicated(keep='first')]\n",
    "\n",
    "    greenness_rooftop.to_csv(DATA_FOLDER / 'greenness_rooftop_30d_cache.csv')\n",
    "    return greenness_rooftop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0f743-16d0-499a-94fa-4a3fad1dc5b6",
   "metadata": {},
   "source": [
    "### Gen-by-fuel for greenness\n",
    "Then we grab all the generation-by-fuel data (and add in PV rooftop from above along the way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f85fea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_features.json') as f:\n",
    "    feat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3487969e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NSW1_Greenness_Tm3d_Mean',\n",
       " 'NSW1_Greenness_Tm7d_Mean',\n",
       " 'NSW1_Greenness_Tm30d_Mean',\n",
       " 'QLD1_Greenness_Tm3d_Mean',\n",
       " 'QLD1_Greenness_Tm7d_Mean',\n",
       " 'QLD1_Greenness_Tm30d_Mean',\n",
       " 'SA1_Greenness_Tm3d_Mean',\n",
       " 'SA1_Greenness_Tm7d_Mean',\n",
       " 'SA1_Greenness_Tm30d_Mean',\n",
       " 'TAS1_Greenness_Tm3d_Mean',\n",
       " 'TAS1_Greenness_Tm7d_Mean',\n",
       " 'TAS1_Greenness_Tm30d_Mean',\n",
       " 'VIC1_Greenness_Tm3d_Mean',\n",
       " 'VIC1_Greenness_Tm7d_Mean',\n",
       " 'VIC1_Greenness_Tm30d_Mean']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in feat if 'Green' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b46b07-584b-4989-9ce0-23609b7955aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gen_by_duid_for_one_day(filename, duids):\n",
    "    df = pd.read_csv(get_subtable_from_file(filename, ',DUNIT,,3'),\n",
    "                     usecols=['SETTLEMENTDATE', 'DUID', 'TOTALCLEARED'],\n",
    "                     parse_dates=['SETTLEMENTDATE'],\n",
    "                     index_col='SETTLEMENTDATE'\n",
    "                    )\n",
    "    df = df.rename(columns={'TOTALCLEARED': 'MW'})\n",
    "    \n",
    "    df = df.join(duids, on='DUID')\n",
    "    \n",
    "    return df\n",
    "    \n",
    "''' \n",
    "assumes gen_by_duid is a dataframe with columns ['SETTLEMENTDATE', 'DUID', 'MW', 'CO2E_ENERGY_SOURCE']\n",
    "'''\n",
    "def calculate_greenness_raw_for_one_day(gen_by_duid, greenness_rooftop):\n",
    "\n",
    "    df = gen_by_duid.copy()\n",
    "    \n",
    "    # drop any loads, only want generators\n",
    "    df = df[df.GENSETTYPE == 'GENERATOR']\n",
    "\n",
    "    # no negatives (saw one once somewhere else, some solar unit in qld)\n",
    "    df['MW'] = df['MW'].clip(lower=0)\n",
    "\n",
    "    # Group by fuel type\n",
    "    df = df.groupby(['SETTLEMENTDATE', 'REGIONID', 'CO2E_ENERGY_SOURCE']).agg({\n",
    "        'MW': np.sum,\n",
    "    }).reset_index()\n",
    "\n",
    "    # # take average across the whole day\n",
    "    # df = df.groupby(['REGIONID', 'CO2E_ENERGY_SOURCE']).agg({\n",
    "    #     'TOTALCLEARED': np.mean,\n",
    "    # }).reset_index()\n",
    "    df = df.set_index('SETTLEMENTDATE')\n",
    "\n",
    "    # feature names are eg VIC1_GEN_Coal\n",
    "    df['name'] = df['REGIONID'] + '_GEN_' + df['CO2E_ENERGY_SOURCE']\n",
    "\n",
    "    df = df.pivot(columns=['name'], values='MW')\n",
    "\n",
    "    # change from 30min to 5min frequency to match PV_forecast\n",
    "    df = df.resample('30min', origin='start').mean()\n",
    "    df.index = df.index + pd.tseries.frequencies.to_offset('25min')  # because SETTLEMENTDATE is end-of-period\n",
    "\n",
    "    # add in rooftop PV data\n",
    "    df = df.join(greenness_rooftop)\n",
    "\n",
    "    # we can assume 0 PV between midnight and 4am!!!  :D\n",
    "    print(f\"isna:{df.isna().sum().sum()}\")\n",
    "    if df.isna().sum().sum() >= 70:\n",
    "        print(df)\n",
    "    assert df.isna().sum().sum() < 70, \"Some NAs in PV data is ok because they're at night, but this is too many\"\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    for region in REGIONIDS:\n",
    "        all_gen = [f'{region}_GEN_{fuel}' for fuel in ['Coal', 'Gas', 'Hydro', 'Solar', 'Wind', 'Rooftop']]\n",
    "        renewable = [f'{region}_GEN_{fuel}' for fuel in ['Hydro', 'Solar', 'Wind', 'Rooftop']]\n",
    "\n",
    "        # add in any missing data, eg SA coal, set to zeros. \n",
    "        for feature in all_gen:\n",
    "            if feature not in df.columns:\n",
    "                df[feature] = 0\n",
    "\n",
    "        df[f'{region}_Greenness_raw'] = df[renewable].sum(axis=1) / df[all_gen].sum(axis=1)            \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754acf8f-dca6-4a43-9dba-03debb0ef3a8",
   "metadata": {},
   "source": [
    "Now, need interconnector flows for the last month too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef43ae5-1e59-4b58-8df6-5c625c13526b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get interconnector net for a recent trading day\n",
    "def get_ics_for_one_day(filename):\n",
    "    df = pd.read_csv(get_subtable_from_file(filename, ',DREGION,,3'),\n",
    "                     usecols=['REGIONID', 'NETINTERCHANGE', 'SETTLEMENTDATE', ],\n",
    "                     parse_dates=['SETTLEMENTDATE'],\n",
    "                     index_col='SETTLEMENTDATE'\n",
    "                    )\n",
    "    # IC_NET is defined to be NETINTERCHANGE * -1. IC_NET: import is +ve generation.\n",
    "    df['NETINTERCHANGE'] = df['NETINTERCHANGE'] * -1\n",
    "    \n",
    "    df = df.pivot(columns='REGIONID', values='NETINTERCHANGE')\n",
    "    df.columns = [f'{region}_IC_NET' for region in df.columns]\n",
    "\n",
    "    # change from 30min to 5min frequency to match PV_forecast\n",
    "    df = df.resample('30min', origin='start').mean()\n",
    "    df.index = df.index + pd.tseries.frequencies.to_offset('25min')  # because SETTLEMENTDATE is end-of-period\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456664c1-d2ea-4a4d-97a8-d3a38189fae3",
   "metadata": {},
   "source": [
    "Finally we put it all together - gen by fuel (incl rooftop pv) & net interchange. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc36ae-6466-43b7-8993-8da9d70ded04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_real_greenness(greenness_inputs):\n",
    "    greenness = pd.DataFrame(index=greenness_inputs.index)\n",
    "\n",
    "\n",
    "    ############\n",
    "    ### Copied from dataset generator. Consider refactoring if making changes. \n",
    "\n",
    "    # Now, un-raw it by adding in interconnector effects\n",
    "    # calcaulte \"IC_Import\" which is all interconnector imports, ignoring any exports\n",
    "    # This is because any exports won't change the greenness for this state\n",
    "    # (this is a bit of an approximation? but close enough since IC flows don't dominate vic/nsw)\n",
    "    # Then, calculate the amount of green energy flowing in, which is IC_import * greenness_raw from the incoming state.\n",
    "    # this is complex for VIC & NSW, easier for other 3 states with only one feeder state. \n",
    "    # with IC_Import and IC_Green_In, we can then calculate the greenness.\n",
    "    gi = greenness_inputs\n",
    "\n",
    "    # QLD/SA/TAS are simpler\n",
    "    gi['QLD1_IC_Import'] = gi['QLD1_IC_NET'].clip(lower=0)\n",
    "    gi['SA1_IC_Import'] = gi['SA1_IC_NET'].clip(lower=0)\n",
    "    gi['TAS1_IC_Import'] = gi['TAS1_IC_NET'].clip(lower=0)\n",
    "\n",
    "    gi['QLD1_IC_Green_In'] = gi['QLD1_IC_Import'] * gi['NSW1_Greenness_raw']\n",
    "    gi['SA1_IC_Green_In'] = gi['SA1_IC_Import'] * gi['VIC1_Greenness_raw']\n",
    "    gi['TAS1_IC_Green_In'] = gi['TAS1_IC_Import'] * gi['VIC1_Greenness_raw']\n",
    "\n",
    "    # NSW1: \n",
    "    gi['NSW1_Import_From_Qld'] = gi['QLD1_IC_NET'].clip(upper=0) * -1\n",
    "    gi['NSW1_IC_Net_From_Vic'] = gi['NSW1_IC_NET'] - (-1) * gi['QLD1_IC_NET']\n",
    "    gi['NSW1_Import_From_Vic'] = gi['NSW1_IC_Net_From_Vic'].clip(lower=0)\n",
    "    gi['NSW1_IC_Import'] = gi['NSW1_Import_From_Qld'] + gi['NSW1_Import_From_Vic']\n",
    "    gi['NSW1_IC_Green_In'] = (gi['NSW1_Import_From_Qld'] * gi['QLD1_Greenness_raw']+ \n",
    "                              gi['NSW1_Import_From_Vic'] * gi['VIC1_Greenness_raw'])\n",
    "\n",
    "    # VIC1:\n",
    "    gi['VIC1_Import_From_Tas'] = gi['TAS1_IC_NET'].clip(upper=0) * -1\n",
    "    gi['VIC1_Import_From_SA']  = gi['SA1_IC_NET'].clip(upper=0) * -1\n",
    "    gi['VIC1_Import_From_NSW'] = gi['NSW1_IC_Net_From_Vic'].clip(upper=0) * -1\n",
    "    gi['VIC1_IC_Import'] = gi['VIC1_Import_From_Tas'] + gi['VIC1_Import_From_SA'] + gi['VIC1_Import_From_NSW']\n",
    "    gi['VIC1_IC_Green_In'] = (gi['VIC1_Import_From_Tas'] * gi['TAS1_Greenness_raw'] +\n",
    "                              gi['VIC1_Import_From_SA']  * gi['SA1_Greenness_raw'] +\n",
    "                              gi['VIC1_Import_From_NSW'] * gi['NSW1_Greenness_raw'])\n",
    "\n",
    "\n",
    "    # calculate greenness for real now we have IC_Import and IC_Green_In\n",
    "    for region in REGIONIDS:\n",
    "        # greenness_inputs[f'{region}_IC_Import'].plot(figsize=(16,5))\n",
    "\n",
    "        renewable = [f'{region}_GEN_{fuel}' for fuel in ['Hydro', 'Solar', 'Wind', 'Rooftop']] + [f'{region}_IC_Green_In']\n",
    "        all_gen = [f'{region}_GEN_{fuel}' for fuel in ['Coal', 'Gas', 'Hydro', 'Solar', 'Wind', 'Rooftop']] + [f'{region}_IC_Import']\n",
    "\n",
    "        # convert to nparray with dtype=object to avoid a warning being thrown\n",
    "        all_gen = np.array(all_gen, dtype=object)\n",
    "        renewable = np.array(renewable, dtype=object)\n",
    "\n",
    "        greenness[f'{region}_Greenness'] = gi[renewable].sum(axis=1) / gi[all_gen].sum(axis=1) \n",
    "\n",
    "    # Let's express everything as a percentage not [0,1]\n",
    "    greenness = greenness * 100\n",
    "\n",
    "    return greenness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2da23-74ce-4189-8ceb-42c7f11e0c55",
   "metadata": {},
   "source": [
    "### Calculate Greenness_Tm30d_Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6f412-7953-4d14-898f-5ca6aa57feda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, get PV data:\n",
    "greenness_rooftop = get_last_30d_of_pv_data()\n",
    "\n",
    "print('Get last 30 days of daily reports:')\n",
    "filenames =[get_latest_file_from_folder('Daily_Reports', nth_most_recent=i) \n",
    "            for i in range(-1, -31, -1)]\n",
    "\n",
    "greenness_month = []  # later becomes a df\n",
    "for filename in filenames:\n",
    "    # filename = filenames[0]\n",
    "\n",
    "    gen_by_duid = get_gen_by_duid_for_one_day(filename, duids)\n",
    "\n",
    "    greenness_inputs = calculate_greenness_raw_for_one_day(gen_by_duid, greenness_rooftop)\n",
    "\n",
    "    greenness_inputs = greenness_inputs.join(get_ics_for_one_day(filename))\n",
    "\n",
    "    greenness_month.append(calculate_real_greenness(greenness_inputs))\n",
    "\n",
    "greenness_month = pd.concat(greenness_month)\n",
    "\n",
    "for region in REGIONIDS:\n",
    "    now_minus_3d = greenness_month.index.max() - pd.Timedelta(3, 'D')\n",
    "    features[f'{region}_Greenness_Tm3d_Mean'] = greenness_month[now_minus_3d:].mean()[f'{region}_Greenness']\n",
    "    now_minus_7d = greenness_month.index.max() - pd.Timedelta(7, 'D')\n",
    "    features[f'{region}_Greenness_Tm7d_Mean'] = greenness_month[now_minus_7d:].mean()[f'{region}_Greenness']\n",
    "    features[f'{region}_Greenness_Tm30d_Mean'] = greenness_month.mean()[f'{region}_Greenness']\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d35880-416d-42d5-8707-07cbb8fd5a53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Greenness at current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4743cce-2202-4745-bf7a-ada1e280cc4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calcuate greenness_raw using features already available\n",
    "greenness_inputs = pd.DataFrame([features])\n",
    "\n",
    "for region in REGIONIDS:\n",
    "    all_gen = [f'{region}_GEN_{fuel}' for fuel in ['Coal', 'Gas', 'Hydro', 'Solar', 'Wind', 'Rooftop']]\n",
    "    renewable = [f'{region}_GEN_{fuel}' for fuel in ['Hydro', 'Solar', 'Wind', 'Rooftop']]\n",
    "\n",
    "    greenness_inputs[f'{region}_Greenness_raw'] = greenness_inputs[renewable].sum(axis=1) / greenness_inputs[all_gen].sum(axis=1)            \n",
    "\n",
    "    \n",
    "greenness_now = calculate_real_greenness(greenness_inputs)\n",
    "for col in greenness_now.columns:\n",
    "    features[col] = greenness_now.iloc[0][col]\n",
    "    \n",
    "    \n",
    "# return features\n",
    "\n",
    "# features\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed18a6-453f-48a9-9c90-2069f9b03043",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2aec1-864c-41b1-8584-9158ec88316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [x for x in columns if 'RG_' not in x]\n",
    "for region in REGIONIDS:\n",
    "    all_features = all_features + [x.replace('RG_', f'{region}_') for x in columns if 'RG_' in x]\n",
    "    \n",
    "len(all_features), len(features), [x for x in all_features if x not in features.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01fdf22-ccc9-465f-99d8-bae651da085f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d298103-4284-4ba5-82ee-6ec143cb6512",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52dea5-8089-4466-ac5f-a589873b2d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names_84 = ['VIC1_AVAILABILITY_Battery Storage', 'VIC1_AVAILABILITY_Coal', 'VIC1_AVAILABILITY_Gas', 'VIC1_AVAILABILITY_Hydro', 'VIC1_AVAILABILITY_Solar', 'VIC1_AVAILABILITY_Wind', 'VIC1_AVAILABLEGENERATION', 'VIC1_AVAILABLEGENERATION_Tp102', 'VIC1_AVAILABLEGENERATION_Tp108', 'VIC1_AVAILABLEGENERATION_Tp60', 'VIC1_AVAILABLEGENERATION_Tp66', 'VIC1_AVAILABLEGENERATION_Tp72', 'VIC1_AVAILABLEGENERATION_Tp78', 'VIC1_AVAILABLEGENERATION_Tp84', 'VIC1_AVAILABLEGENERATION_Tp90', 'VIC1_AVAILABLEGENERATION_Tp96', 'VIC1_GENERATION', 'VIC1_GEN_Battery Storage', 'VIC1_GEN_Coal', 'VIC1_GEN_Gas', 'VIC1_GEN_Hydro', 'VIC1_GEN_Rooftop', 'VIC1_GEN_Rooftop_Tp102', 'VIC1_GEN_Rooftop_Tp108', 'VIC1_GEN_Rooftop_Tp60', 'VIC1_GEN_Rooftop_Tp66', 'VIC1_GEN_Rooftop_Tp72', 'VIC1_GEN_Rooftop_Tp78', 'VIC1_GEN_Rooftop_Tp84', 'VIC1_GEN_Rooftop_Tp90', 'VIC1_GEN_Rooftop_Tp96', 'VIC1_GEN_Solar', 'VIC1_GEN_Solar_Tp102', 'VIC1_GEN_Solar_Tp108', 'VIC1_GEN_Solar_Tp60', 'VIC1_GEN_Solar_Tp66', 'VIC1_GEN_Solar_Tp72', 'VIC1_GEN_Solar_Tp78', 'VIC1_GEN_Solar_Tp84', 'VIC1_GEN_Solar_Tp90', 'VIC1_GEN_Solar_Tp96', 'VIC1_GEN_Wind', 'VIC1_GEN_Wind_Tp102', 'VIC1_GEN_Wind_Tp108', 'VIC1_GEN_Wind_Tp60', 'VIC1_GEN_Wind_Tp66', 'VIC1_GEN_Wind_Tp72', 'VIC1_GEN_Wind_Tp78', 'VIC1_GEN_Wind_Tp84', 'VIC1_GEN_Wind_Tp90', 'VIC1_GEN_Wind_Tp96', 'VIC1_Greenness', 'VIC1_Greenness_Tm30d_Mean', 'VIC1_Greenness_Tm3d_Mean', 'VIC1_Greenness_Tm7d_Mean', 'VIC1_IC_Export_Limit', 'VIC1_IC_Import_Limit', 'VIC1_IC_NET', 'VIC1_Predis_Price_Tp12', 'VIC1_Predis_Price_Tp16', 'VIC1_Predis_Price_Tp4', 'VIC1_Predis_Price_Tp8', 'VIC1_Predis_Price_max16to40h', 'VIC1_Predis_Price_min16to40h', 'VIC1_Price', 'VIC1_Price_Tm1', 'VIC1_Price_Tm10', 'VIC1_Price_Tm12', 'VIC1_Price_Tm14', 'VIC1_Price_Tm16', 'VIC1_Price_Tm168', 'VIC1_Price_Tm18', 'VIC1_Price_Tm2', 'VIC1_Price_Tm20', 'VIC1_Price_Tm22', 'VIC1_Price_Tm24', 'VIC1_Price_Tm28', 'VIC1_Price_Tm30d_15thP', 'VIC1_Price_Tm30d_85thP', 'VIC1_Price_Tm30d_Median', 'VIC1_Price_Tm32', 'VIC1_Price_Tm36', 'VIC1_Price_Tm4', 'VIC1_Price_Tm40', 'VIC1_Price_Tm44', 'VIC1_Price_Tm48', 'VIC1_Price_Tm52', 'VIC1_Price_Tm56', 'VIC1_Price_Tm6', 'VIC1_Price_Tm60', 'VIC1_Price_Tm64', 'VIC1_Price_Tm68', 'VIC1_Price_Tm72', 'VIC1_Price_Tm7d_15thP', 'VIC1_Price_Tm7d_85thP', 'VIC1_Price_Tm7d_Median', 'VIC1_Price_Tm8', 'VIC1_TOTALDEMAND', 'VIC1_TOTALDEMAND_Tp102', 'VIC1_TOTALDEMAND_Tp108', 'VIC1_TOTALDEMAND_Tp60', 'VIC1_TOTALDEMAND_Tp66', 'VIC1_TOTALDEMAND_Tp72', 'VIC1_TOTALDEMAND_Tp78', 'VIC1_TOTALDEMAND_Tp84', 'VIC1_TOTALDEMAND_Tp90', 'VIC1_TOTALDEMAND_Tp96', 'VIC1_W_day_max_temperature', 'VIC1_W_day_max_temperature_Tp72', 'VIC1_W_day_max_temperature_Tp96', 'VIC1_W_temperature', 'VIC1_is_workday', 'VIC1_is_workday_Tp72', 'VIC1_is_workday_Tp96', 'hour', 'hours_since_2010', 'is_weekend', 'month', 'quarter', 'weekday', 'year']\n",
    "test_vals_84 = [0.0, 6165.0, 1330.0, 1917.0, 0.0, 0.0, 9412.0, 9492.0, 9531.0, 10030.0, 10030.0, 10020.0, 9650.0, 10020.0, 10010.0, 9825.0, 6018.0, 0.0, 6018.0, 0.666700005531311, 1.8950000666958025e-14, 0.0, 0.06875000149011612, 4.566999912261963, 11.510000228881836, 11.579999923706055, 3.1459999084472656, 0.13750000298023224, 6.711999893188477, 7.136000156402588, 1.312000036239624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6165000200271606, 4.0320000648498535, 4.007999897003174, 4.5929999351501465, -1352.0, 428.29998779296875, -1229.0, 30.6299991607666, 52.5099983215332, 12.029999732971191, 23.389999389648438, 52.5099983215332, 17.90999984741211, 18.899999618530273, 17.559999465942383, 52.95000076293945, 43.75, 36.349998474121094, 21.540000915527344, 19.440000534057617, 18.549999237060547, 14.989999771118164, 17.68000030517578, 19.799999237060547, 26.639999389648438, 40.209999084472656, 15.539999961853027, 35.0099983215332, 22.280000686645508, 46.150001525878906, 25.06999969482422, 28.670000076293945, 21.139999389648438, 9.100000381469727, 19.100000381469727, 21.420000076293945, 29.600000381469727, 29.700000762939453, 30.18000030517578, 23.989999771118164, 18.299999237060547, 20.149999618530273, 18.450000762939453, 37.91999816894531, 26.059999465942383, 39.70000076293945, 4790.0, 5791.0, 6561.0, 8516.0, 8855.0, 8650.0, 6440.0, 7872.0, 7579.0, 6782.0, 22.780000686645508, 26.889999389648438, 20.43000030517578, 17.959999084472656, 1.0, 1.0, 1.0, 0.0, 8640.0, 0.0, 2.0, 1.0, 0.0, 0.0]\n",
    "test_features_84 = {col:val for col,val in list(zip(column_names_84, test_vals_84))}\n",
    "\n",
    "column_names = ['VIC1_AVAILABILITY_Battery Storage', 'VIC1_AVAILABILITY_Coal', 'VIC1_AVAILABILITY_Gas', 'VIC1_AVAILABILITY_Hydro', 'VIC1_AVAILABILITY_Solar', 'VIC1_AVAILABILITY_Wind', 'VIC1_AVAILABLEGENERATION', 'VIC1_AVAILABLEGENERATION_Tp102', 'VIC1_AVAILABLEGENERATION_Tp108', 'VIC1_AVAILABLEGENERATION_Tp114', 'VIC1_AVAILABLEGENERATION_Tp12', 'VIC1_AVAILABLEGENERATION_Tp120', 'VIC1_AVAILABLEGENERATION_Tp126', 'VIC1_AVAILABLEGENERATION_Tp132', 'VIC1_AVAILABLEGENERATION_Tp138', 'VIC1_AVAILABLEGENERATION_Tp144', 'VIC1_AVAILABLEGENERATION_Tp150', 'VIC1_AVAILABLEGENERATION_Tp156', 'VIC1_AVAILABLEGENERATION_Tp162', 'VIC1_AVAILABLEGENERATION_Tp168', 'VIC1_AVAILABLEGENERATION_Tp18', 'VIC1_AVAILABLEGENERATION_Tp24', 'VIC1_AVAILABLEGENERATION_Tp30', 'VIC1_AVAILABLEGENERATION_Tp36', 'VIC1_AVAILABLEGENERATION_Tp42', 'VIC1_AVAILABLEGENERATION_Tp48', 'VIC1_AVAILABLEGENERATION_Tp54', 'VIC1_AVAILABLEGENERATION_Tp6', 'VIC1_AVAILABLEGENERATION_Tp60', 'VIC1_AVAILABLEGENERATION_Tp66', 'VIC1_AVAILABLEGENERATION_Tp72', 'VIC1_AVAILABLEGENERATION_Tp78', 'VIC1_AVAILABLEGENERATION_Tp84', 'VIC1_AVAILABLEGENERATION_Tp90', 'VIC1_AVAILABLEGENERATION_Tp96', 'VIC1_GENERATION', 'VIC1_GEN_Battery Storage', 'VIC1_GEN_Coal', 'VIC1_GEN_Gas', 'VIC1_GEN_Hydro', 'VIC1_GEN_Rooftop', 'VIC1_GEN_Rooftop_Tp102', 'VIC1_GEN_Rooftop_Tp108', 'VIC1_GEN_Rooftop_Tp114', 'VIC1_GEN_Rooftop_Tp12', 'VIC1_GEN_Rooftop_Tp120', 'VIC1_GEN_Rooftop_Tp126', 'VIC1_GEN_Rooftop_Tp132', 'VIC1_GEN_Rooftop_Tp138', 'VIC1_GEN_Rooftop_Tp144', 'VIC1_GEN_Rooftop_Tp150', 'VIC1_GEN_Rooftop_Tp156', 'VIC1_GEN_Rooftop_Tp162', 'VIC1_GEN_Rooftop_Tp168', 'VIC1_GEN_Rooftop_Tp18', 'VIC1_GEN_Rooftop_Tp24', 'VIC1_GEN_Rooftop_Tp30', 'VIC1_GEN_Rooftop_Tp36', 'VIC1_GEN_Rooftop_Tp42', 'VIC1_GEN_Rooftop_Tp48', 'VIC1_GEN_Rooftop_Tp54', 'VIC1_GEN_Rooftop_Tp6', 'VIC1_GEN_Rooftop_Tp60', 'VIC1_GEN_Rooftop_Tp66', 'VIC1_GEN_Rooftop_Tp72', 'VIC1_GEN_Rooftop_Tp78', 'VIC1_GEN_Rooftop_Tp84', 'VIC1_GEN_Rooftop_Tp90', 'VIC1_GEN_Rooftop_Tp96', 'VIC1_GEN_Solar', 'VIC1_GEN_Solar_Tp102', 'VIC1_GEN_Solar_Tp108', 'VIC1_GEN_Solar_Tp114', 'VIC1_GEN_Solar_Tp12', 'VIC1_GEN_Solar_Tp120', 'VIC1_GEN_Solar_Tp126', 'VIC1_GEN_Solar_Tp132', 'VIC1_GEN_Solar_Tp138', 'VIC1_GEN_Solar_Tp144', 'VIC1_GEN_Solar_Tp150', 'VIC1_GEN_Solar_Tp156', 'VIC1_GEN_Solar_Tp162', 'VIC1_GEN_Solar_Tp168', 'VIC1_GEN_Solar_Tp18', 'VIC1_GEN_Solar_Tp24', 'VIC1_GEN_Solar_Tp30', 'VIC1_GEN_Solar_Tp36', 'VIC1_GEN_Solar_Tp42', 'VIC1_GEN_Solar_Tp48', 'VIC1_GEN_Solar_Tp54', 'VIC1_GEN_Solar_Tp6', 'VIC1_GEN_Solar_Tp60', 'VIC1_GEN_Solar_Tp66', 'VIC1_GEN_Solar_Tp72', 'VIC1_GEN_Solar_Tp78', 'VIC1_GEN_Solar_Tp84', 'VIC1_GEN_Solar_Tp90', 'VIC1_GEN_Solar_Tp96', 'VIC1_GEN_Wind', 'VIC1_GEN_Wind_Tp102', 'VIC1_GEN_Wind_Tp108', 'VIC1_GEN_Wind_Tp114', 'VIC1_GEN_Wind_Tp12', 'VIC1_GEN_Wind_Tp120', 'VIC1_GEN_Wind_Tp126', 'VIC1_GEN_Wind_Tp132', 'VIC1_GEN_Wind_Tp138', 'VIC1_GEN_Wind_Tp144', 'VIC1_GEN_Wind_Tp150', 'VIC1_GEN_Wind_Tp156', 'VIC1_GEN_Wind_Tp162', 'VIC1_GEN_Wind_Tp168', 'VIC1_GEN_Wind_Tp18', 'VIC1_GEN_Wind_Tp24', 'VIC1_GEN_Wind_Tp30', 'VIC1_GEN_Wind_Tp36', 'VIC1_GEN_Wind_Tp42', 'VIC1_GEN_Wind_Tp48', 'VIC1_GEN_Wind_Tp54', 'VIC1_GEN_Wind_Tp6', 'VIC1_GEN_Wind_Tp60', 'VIC1_GEN_Wind_Tp66', 'VIC1_GEN_Wind_Tp72', 'VIC1_GEN_Wind_Tp78', 'VIC1_GEN_Wind_Tp84', 'VIC1_GEN_Wind_Tp90', 'VIC1_GEN_Wind_Tp96', 'VIC1_Greenness', 'VIC1_Greenness_Tm30d_Mean', 'VIC1_Greenness_Tm3d_Mean', 'VIC1_Greenness_Tm7d_Mean', 'VIC1_IC_Export_Limit', 'VIC1_IC_Import_Limit', 'VIC1_IC_NET', 'VIC1_Predis_Price_Tp12', 'VIC1_Predis_Price_Tp16', 'VIC1_Predis_Price_Tp4', 'VIC1_Predis_Price_Tp8', 'VIC1_Predis_Price_max16to40h', 'VIC1_Predis_Price_min16to40h', 'VIC1_Price', 'VIC1_Price_Tm1', 'VIC1_Price_Tm10', 'VIC1_Price_Tm12', 'VIC1_Price_Tm14', 'VIC1_Price_Tm16', 'VIC1_Price_Tm168', 'VIC1_Price_Tm18', 'VIC1_Price_Tm2', 'VIC1_Price_Tm20', 'VIC1_Price_Tm22', 'VIC1_Price_Tm24', 'VIC1_Price_Tm28', 'VIC1_Price_Tm30d_15thP', 'VIC1_Price_Tm30d_85thP', 'VIC1_Price_Tm30d_Median', 'VIC1_Price_Tm32', 'VIC1_Price_Tm36', 'VIC1_Price_Tm4', 'VIC1_Price_Tm40', 'VIC1_Price_Tm44', 'VIC1_Price_Tm48', 'VIC1_Price_Tm52', 'VIC1_Price_Tm56', 'VIC1_Price_Tm6', 'VIC1_Price_Tm60', 'VIC1_Price_Tm64', 'VIC1_Price_Tm68', 'VIC1_Price_Tm72', 'VIC1_Price_Tm7d_15thP', 'VIC1_Price_Tm7d_85thP', 'VIC1_Price_Tm7d_Median', 'VIC1_Price_Tm8', 'VIC1_Price_Tp84', 'VIC1_TOTALDEMAND', 'VIC1_TOTALDEMAND_Tp102', 'VIC1_TOTALDEMAND_Tp108', 'VIC1_TOTALDEMAND_Tp114', 'VIC1_TOTALDEMAND_Tp12', 'VIC1_TOTALDEMAND_Tp120', 'VIC1_TOTALDEMAND_Tp126', 'VIC1_TOTALDEMAND_Tp132', 'VIC1_TOTALDEMAND_Tp138', 'VIC1_TOTALDEMAND_Tp144', 'VIC1_TOTALDEMAND_Tp150', 'VIC1_TOTALDEMAND_Tp156', 'VIC1_TOTALDEMAND_Tp162', 'VIC1_TOTALDEMAND_Tp168', 'VIC1_TOTALDEMAND_Tp18', 'VIC1_TOTALDEMAND_Tp24', 'VIC1_TOTALDEMAND_Tp30', 'VIC1_TOTALDEMAND_Tp36', 'VIC1_TOTALDEMAND_Tp42', 'VIC1_TOTALDEMAND_Tp48', 'VIC1_TOTALDEMAND_Tp54', 'VIC1_TOTALDEMAND_Tp6', 'VIC1_TOTALDEMAND_Tp60', 'VIC1_TOTALDEMAND_Tp66', 'VIC1_TOTALDEMAND_Tp72', 'VIC1_TOTALDEMAND_Tp78', 'VIC1_TOTALDEMAND_Tp84', 'VIC1_TOTALDEMAND_Tp90', 'VIC1_TOTALDEMAND_Tp96', 'VIC1_W_day_max_temperature', 'VIC1_W_day_max_temperature_Tp120', 'VIC1_W_day_max_temperature_Tp144', 'VIC1_W_day_max_temperature_Tp168', 'VIC1_W_day_max_temperature_Tp24', 'VIC1_W_day_max_temperature_Tp48', 'VIC1_W_day_max_temperature_Tp72', 'VIC1_W_day_max_temperature_Tp96', 'VIC1_W_temperature', 'VIC1_is_workday', 'VIC1_is_workday_Tp120', 'VIC1_is_workday_Tp144', 'VIC1_is_workday_Tp168', 'VIC1_is_workday_Tp24', 'VIC1_is_workday_Tp48', 'VIC1_is_workday_Tp72', 'VIC1_is_workday_Tp96', 'day', 'hour', 'hours_since_2010', 'is_augment_row', 'is_validation_set', 'is_weekend', 'month', 'quarter', 'validation_set', 'weekday', 'year']\n",
    "test_vals = [0.0, 6165.0, 1330.0, 1917.0, 0.0, 0.0, 9412.0, 9492.0, 9531.0, 9563.0, 9477.0, 9465.0, 9116.0, 8975.0, 9228.0, 9269.0, 9680.0, 9672.0, 9692.0, 9694.0, 9448.0, 9462.0, 9477.0, 10010.0, 10070.0, 10080.0, 9612.0, 9473.0, 10030.0, 10030.0, 10020.0, 9650.0, 10020.0, 10010.0, 9825.0, 6018.0, 0.0, 6018.0, 0.666700005531311, 1.8950000666958025e-14, 0.0, 0.06875000149011612, 4.566999912261963, 5.7210001945495605, 11.199999809265137, 2.4059998989105225, 0.2062000036239624, 8.664999961853027, 9.326000213623047, 3.382999897003174, 0.22920000553131104, 11.680000305175781, 12.010000228881836, 3.509999990463257, 11.229999542236328, 3.430999994277954, 0.3021000027656555, 10.539999961853027, 10.770000457763672, 2.808000087738037, 0.3021000027656555, 0.3021000027656555, 11.510000228881836, 11.579999923706055, 3.1459999084472656, 0.13750000298023224, 6.711999893188477, 7.136000156402588, 1.312000036239624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6165000200271606, 4.0320000648498535, 4.007999897003174, 4.5929999351501465, -1352.0, 428.29998779296875, -1229.0, 30.6299991607666, 52.5099983215332, 12.029999732971191, 23.389999389648438, 52.5099983215332, 17.90999984741211, 18.899999618530273, 17.559999465942383, 52.95000076293945, 43.75, 36.349998474121094, 21.540000915527344, 19.440000534057617, 18.549999237060547, 14.989999771118164, 17.68000030517578, 19.799999237060547, 26.639999389648438, 40.209999084472656, 15.539999961853027, 35.0099983215332, 22.280000686645508, 46.150001525878906, 25.06999969482422, 28.670000076293945, 21.139999389648438, 9.100000381469727, 19.100000381469727, 21.420000076293945, 29.600000381469727, 29.700000762939453, 30.18000030517578, 23.989999771118164, 18.299999237060547, 20.149999618530273, 18.450000762939453, 37.91999816894531, 26.059999465942383, 39.70000076293945, 21.809999465942383, 4790.0, 5791.0, 6561.0, 6461.0, 6883.0, 5713.0, 4801.0, 5533.0, 5648.0, 5403.0, 4725.0, 5917.0, 7087.0, 7012.0, 7161.0, 6429.0, 5664.0, 8121.0, 8868.0, 8310.0, 5971.0, 5470.0, 8516.0, 8855.0, 8650.0, 6440.0, 7872.0, 7579.0, 6782.0, 22.780000686645508, 24.6299991607666, 28.34000015258789, 31.389999389648438, 32.08000183105469, 31.920000076293945, 26.889999389648438, 20.43000030517578, 17.959999084472656, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 8640.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0]\n",
    "test_features = {col:val for col,val in list(zip(column_names, test_vals))}\n",
    "# Add a 2nd region to the test dataset.\n",
    "other_region = {f\"TAS1_{col[5:]}\": test_features[col] for col in column_names if 'VIC1_' in col}\n",
    "test_features = test_features | other_region \n",
    "\n",
    "def get_test_features():\n",
    "    return test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f60ae-1f06-4308-9bec-b7c8fda0dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: predict NN with dummy values\n",
    "learner = load_fastai_nn_model('VIC1_Price_Tp84')\n",
    "\n",
    "column_names_84 = ['VIC1_AVAILABILITY_Battery Storage', 'VIC1_AVAILABILITY_Coal', 'VIC1_AVAILABILITY_Gas', 'VIC1_AVAILABILITY_Hydro', 'VIC1_AVAILABILITY_Solar', 'VIC1_AVAILABILITY_Wind', 'VIC1_AVAILABLEGENERATION', 'VIC1_AVAILABLEGENERATION_Tp102', 'VIC1_AVAILABLEGENERATION_Tp108', 'VIC1_AVAILABLEGENERATION_Tp60', 'VIC1_AVAILABLEGENERATION_Tp66', 'VIC1_AVAILABLEGENERATION_Tp72', 'VIC1_AVAILABLEGENERATION_Tp78', 'VIC1_AVAILABLEGENERATION_Tp84', 'VIC1_AVAILABLEGENERATION_Tp90', 'VIC1_AVAILABLEGENERATION_Tp96', 'VIC1_GENERATION', 'VIC1_GEN_Battery Storage', 'VIC1_GEN_Coal', 'VIC1_GEN_Gas', 'VIC1_GEN_Hydro', 'VIC1_GEN_Rooftop', 'VIC1_GEN_Rooftop_Tp102', 'VIC1_GEN_Rooftop_Tp108', 'VIC1_GEN_Rooftop_Tp60', 'VIC1_GEN_Rooftop_Tp66', 'VIC1_GEN_Rooftop_Tp72', 'VIC1_GEN_Rooftop_Tp78', 'VIC1_GEN_Rooftop_Tp84', 'VIC1_GEN_Rooftop_Tp90', 'VIC1_GEN_Rooftop_Tp96', 'VIC1_GEN_Solar', 'VIC1_GEN_Solar_Tp102', 'VIC1_GEN_Solar_Tp108', 'VIC1_GEN_Solar_Tp60', 'VIC1_GEN_Solar_Tp66', 'VIC1_GEN_Solar_Tp72', 'VIC1_GEN_Solar_Tp78', 'VIC1_GEN_Solar_Tp84', 'VIC1_GEN_Solar_Tp90', 'VIC1_GEN_Solar_Tp96', 'VIC1_GEN_Wind', 'VIC1_GEN_Wind_Tp102', 'VIC1_GEN_Wind_Tp108', 'VIC1_GEN_Wind_Tp60', 'VIC1_GEN_Wind_Tp66', 'VIC1_GEN_Wind_Tp72', 'VIC1_GEN_Wind_Tp78', 'VIC1_GEN_Wind_Tp84', 'VIC1_GEN_Wind_Tp90', 'VIC1_GEN_Wind_Tp96', 'VIC1_Greenness', 'VIC1_Greenness_Tm30d_Mean', 'VIC1_Greenness_Tm3d_Mean', 'VIC1_Greenness_Tm7d_Mean', 'VIC1_IC_Export_Limit', 'VIC1_IC_Import_Limit', 'VIC1_IC_NET', 'VIC1_Predis_Price_Tp12', 'VIC1_Predis_Price_Tp16', 'VIC1_Predis_Price_Tp4', 'VIC1_Predis_Price_Tp8', 'VIC1_Predis_Price_max16to40h', 'VIC1_Predis_Price_min16to40h', 'VIC1_Price', 'VIC1_Price_Tm1', 'VIC1_Price_Tm10', 'VIC1_Price_Tm12', 'VIC1_Price_Tm14', 'VIC1_Price_Tm16', 'VIC1_Price_Tm168', 'VIC1_Price_Tm18', 'VIC1_Price_Tm2', 'VIC1_Price_Tm20', 'VIC1_Price_Tm22', 'VIC1_Price_Tm24', 'VIC1_Price_Tm28', 'VIC1_Price_Tm30d_15thP', 'VIC1_Price_Tm30d_85thP', 'VIC1_Price_Tm30d_Median', 'VIC1_Price_Tm32', 'VIC1_Price_Tm36', 'VIC1_Price_Tm4', 'VIC1_Price_Tm40', 'VIC1_Price_Tm44', 'VIC1_Price_Tm48', 'VIC1_Price_Tm52', 'VIC1_Price_Tm56', 'VIC1_Price_Tm6', 'VIC1_Price_Tm60', 'VIC1_Price_Tm64', 'VIC1_Price_Tm68', 'VIC1_Price_Tm72', 'VIC1_Price_Tm7d_15thP', 'VIC1_Price_Tm7d_85thP', 'VIC1_Price_Tm7d_Median', 'VIC1_Price_Tm8', 'VIC1_TOTALDEMAND', 'VIC1_TOTALDEMAND_Tp102', 'VIC1_TOTALDEMAND_Tp108', 'VIC1_TOTALDEMAND_Tp60', 'VIC1_TOTALDEMAND_Tp66', 'VIC1_TOTALDEMAND_Tp72', 'VIC1_TOTALDEMAND_Tp78', 'VIC1_TOTALDEMAND_Tp84', 'VIC1_TOTALDEMAND_Tp90', 'VIC1_TOTALDEMAND_Tp96', 'VIC1_W_day_max_temperature', 'VIC1_W_day_max_temperature_Tp72', 'VIC1_W_day_max_temperature_Tp96', 'VIC1_W_temperature', 'VIC1_is_workday', 'VIC1_is_workday_Tp72', 'VIC1_is_workday_Tp96', 'hour', 'hours_since_2010', 'is_weekend', 'month', 'quarter', 'weekday', 'year']\n",
    "test_vals_84 = [0.0, 6165.0, 1330.0, 1917.0, 0.0, 0.0, 9412.0, 9492.0, 9531.0, 10030.0, 10030.0, 10020.0, 9650.0, 10020.0, 10010.0, 9825.0, 6018.0, 0.0, 6018.0, 0.666700005531311, 1.8950000666958025e-14, 0.0, 0.06875000149011612, 4.566999912261963, 11.510000228881836, 11.579999923706055, 3.1459999084472656, 0.13750000298023224, 6.711999893188477, 7.136000156402588, 1.312000036239624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6165000200271606, 4.0320000648498535, 4.007999897003174, 4.5929999351501465, -1352.0, 428.29998779296875, -1229.0, 30.6299991607666, 52.5099983215332, 12.029999732971191, 23.389999389648438, 52.5099983215332, 17.90999984741211, 18.899999618530273, 17.559999465942383, 52.95000076293945, 43.75, 36.349998474121094, 21.540000915527344, 19.440000534057617, 18.549999237060547, 14.989999771118164, 17.68000030517578, 19.799999237060547, 26.639999389648438, 40.209999084472656, 15.539999961853027, 35.0099983215332, 22.280000686645508, 46.150001525878906, 25.06999969482422, 28.670000076293945, 21.139999389648438, 9.100000381469727, 19.100000381469727, 21.420000076293945, 29.600000381469727, 29.700000762939453, 30.18000030517578, 23.989999771118164, 18.299999237060547, 20.149999618530273, 18.450000762939453, 37.91999816894531, 26.059999465942383, 39.70000076293945, 4790.0, 5791.0, 6561.0, 8516.0, 8855.0, 8650.0, 6440.0, 7872.0, 7579.0, 6782.0, 22.780000686645508, 26.889999389648438, 20.43000030517578, 17.959999084472656, 1.0, 1.0, 1.0, 0.0, 8640.0, 0.0, 2.0, 1.0, 0.0, 0.0]\n",
    "\n",
    "X = pd.Series(test_vals_84, index=column_names_84)\n",
    "learner.predict(X)[2].item()\n",
    "# 32.810882568359375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88373e60-d5eb-4226-a0f1-754492180622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: predict XGB with dummy values\n",
    "xgb = load_xgb_model('VIC1_Price_Tp84')\n",
    "\n",
    "column_names_84 = ['VIC1_AVAILABILITY_Battery Storage', 'VIC1_AVAILABILITY_Coal', 'VIC1_AVAILABILITY_Gas', 'VIC1_AVAILABILITY_Hydro', 'VIC1_AVAILABILITY_Solar', 'VIC1_AVAILABILITY_Wind', 'VIC1_AVAILABLEGENERATION', 'VIC1_AVAILABLEGENERATION_Tp102', 'VIC1_AVAILABLEGENERATION_Tp108', 'VIC1_AVAILABLEGENERATION_Tp60', 'VIC1_AVAILABLEGENERATION_Tp66', 'VIC1_AVAILABLEGENERATION_Tp72', 'VIC1_AVAILABLEGENERATION_Tp78', 'VIC1_AVAILABLEGENERATION_Tp84', 'VIC1_AVAILABLEGENERATION_Tp90', 'VIC1_AVAILABLEGENERATION_Tp96', 'VIC1_GENERATION', 'VIC1_GEN_Battery Storage', 'VIC1_GEN_Coal', 'VIC1_GEN_Gas', 'VIC1_GEN_Hydro', 'VIC1_GEN_Rooftop', 'VIC1_GEN_Rooftop_Tp102', 'VIC1_GEN_Rooftop_Tp108', 'VIC1_GEN_Rooftop_Tp60', 'VIC1_GEN_Rooftop_Tp66', 'VIC1_GEN_Rooftop_Tp72', 'VIC1_GEN_Rooftop_Tp78', 'VIC1_GEN_Rooftop_Tp84', 'VIC1_GEN_Rooftop_Tp90', 'VIC1_GEN_Rooftop_Tp96', 'VIC1_GEN_Solar', 'VIC1_GEN_Solar_Tp102', 'VIC1_GEN_Solar_Tp108', 'VIC1_GEN_Solar_Tp60', 'VIC1_GEN_Solar_Tp66', 'VIC1_GEN_Solar_Tp72', 'VIC1_GEN_Solar_Tp78', 'VIC1_GEN_Solar_Tp84', 'VIC1_GEN_Solar_Tp90', 'VIC1_GEN_Solar_Tp96', 'VIC1_GEN_Wind', 'VIC1_GEN_Wind_Tp102', 'VIC1_GEN_Wind_Tp108', 'VIC1_GEN_Wind_Tp60', 'VIC1_GEN_Wind_Tp66', 'VIC1_GEN_Wind_Tp72', 'VIC1_GEN_Wind_Tp78', 'VIC1_GEN_Wind_Tp84', 'VIC1_GEN_Wind_Tp90', 'VIC1_GEN_Wind_Tp96', 'VIC1_Greenness', 'VIC1_Greenness_Tm30d_Mean', 'VIC1_Greenness_Tm3d_Mean', 'VIC1_Greenness_Tm7d_Mean', 'VIC1_IC_Export_Limit', 'VIC1_IC_Import_Limit', 'VIC1_IC_NET', 'VIC1_Predis_Price_Tp12', 'VIC1_Predis_Price_Tp16', 'VIC1_Predis_Price_Tp4', 'VIC1_Predis_Price_Tp8', 'VIC1_Predis_Price_max16to40h', 'VIC1_Predis_Price_min16to40h', 'VIC1_Price', 'VIC1_Price_Tm1', 'VIC1_Price_Tm10', 'VIC1_Price_Tm12', 'VIC1_Price_Tm14', 'VIC1_Price_Tm16', 'VIC1_Price_Tm168', 'VIC1_Price_Tm18', 'VIC1_Price_Tm2', 'VIC1_Price_Tm20', 'VIC1_Price_Tm22', 'VIC1_Price_Tm24', 'VIC1_Price_Tm28', 'VIC1_Price_Tm30d_15thP', 'VIC1_Price_Tm30d_85thP', 'VIC1_Price_Tm30d_Median', 'VIC1_Price_Tm32', 'VIC1_Price_Tm36', 'VIC1_Price_Tm4', 'VIC1_Price_Tm40', 'VIC1_Price_Tm44', 'VIC1_Price_Tm48', 'VIC1_Price_Tm52', 'VIC1_Price_Tm56', 'VIC1_Price_Tm6', 'VIC1_Price_Tm60', 'VIC1_Price_Tm64', 'VIC1_Price_Tm68', 'VIC1_Price_Tm72', 'VIC1_Price_Tm7d_15thP', 'VIC1_Price_Tm7d_85thP', 'VIC1_Price_Tm7d_Median', 'VIC1_Price_Tm8', 'VIC1_TOTALDEMAND', 'VIC1_TOTALDEMAND_Tp102', 'VIC1_TOTALDEMAND_Tp108', 'VIC1_TOTALDEMAND_Tp60', 'VIC1_TOTALDEMAND_Tp66', 'VIC1_TOTALDEMAND_Tp72', 'VIC1_TOTALDEMAND_Tp78', 'VIC1_TOTALDEMAND_Tp84', 'VIC1_TOTALDEMAND_Tp90', 'VIC1_TOTALDEMAND_Tp96', 'VIC1_W_day_max_temperature', 'VIC1_W_day_max_temperature_Tp72', 'VIC1_W_day_max_temperature_Tp96', 'VIC1_W_temperature', 'VIC1_is_workday', 'VIC1_is_workday_Tp72', 'VIC1_is_workday_Tp96', 'hour', 'hours_since_2010', 'is_weekend', 'month', 'quarter', 'weekday', 'year']\n",
    "test_vals_84 = [0.0, 6165.0, 1330.0, 1917.0, 0.0, 0.0, 9412.0, 9492.0, 9531.0, 10030.0, 10030.0, 10020.0, 9650.0, 10020.0, 10010.0, 9825.0, 6018.0, 0.0, 6018.0, 0.666700005531311, 1.8950000666958025e-14, 0.0, 0.06875000149011612, 4.566999912261963, 11.510000228881836, 11.579999923706055, 3.1459999084472656, 0.13750000298023224, 6.711999893188477, 7.136000156402588, 1.312000036239624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6165000200271606, 4.0320000648498535, 4.007999897003174, 4.5929999351501465, -1352.0, 428.29998779296875, -1229.0, 30.6299991607666, 52.5099983215332, 12.029999732971191, 23.389999389648438, 52.5099983215332, 17.90999984741211, 18.899999618530273, 17.559999465942383, 52.95000076293945, 43.75, 36.349998474121094, 21.540000915527344, 19.440000534057617, 18.549999237060547, 14.989999771118164, 17.68000030517578, 19.799999237060547, 26.639999389648438, 40.209999084472656, 15.539999961853027, 35.0099983215332, 22.280000686645508, 46.150001525878906, 25.06999969482422, 28.670000076293945, 21.139999389648438, 9.100000381469727, 19.100000381469727, 21.420000076293945, 29.600000381469727, 29.700000762939453, 30.18000030517578, 23.989999771118164, 18.299999237060547, 20.149999618530273, 18.450000762939453, 37.91999816894531, 26.059999465942383, 39.70000076293945, 4790.0, 5791.0, 6561.0, 8516.0, 8855.0, 8650.0, 6440.0, 7872.0, 7579.0, 6782.0, 22.780000686645508, 26.889999389648438, 20.43000030517578, 17.959999084472656, 1.0, 1.0, 1.0, 0.0, 8640.0, 0.0, 2.0, 1.0, 0.0, 0.0]\n",
    "\n",
    "X = pd.DataFrame([test_vals_84], columns=column_names_84)\n",
    "# X = xgboost.DMatrix(np.array(vals).reshape(1,286), label=column_names)\n",
    "xgb.predict(X)[0]\n",
    "# 55.13684"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7621a9-4751-41d1-a73f-f6202a24a5db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d50879-4851-45e5-8633-95790bd350eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fastai_nn_model(model_id):\n",
    "    return fastai.load_learner(MODELS_FOLDER / f\"{model_id}_nn.pkl\")\n",
    "\n",
    "def load_xgb_model(model_id):\n",
    "    xgb = xgboost.XGBRegressor()\n",
    "    xgb.load_model(MODELS_FOLDER / f\"{model_id}_xgb.txt\")\n",
    "    xgb.predictor = 'cpu_predictor'  # would be gpu_predictor otherwise, don't know if gpu is available on lambda\n",
    "    return xgb\n",
    "\n",
    "def predict_fastai_nn(model_id, data):\n",
    "    model = load_fastai_nn_model(model_id)\n",
    "    features = pd.Series(data)\n",
    "    return model.predict(features)[2].item()\n",
    "\n",
    "def predict_xgb(model_id, data):\n",
    "    model = load_xgb_model(model_id)\n",
    "    features = pd.DataFrame([data])\n",
    "    return model.predict(features)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382b693-b036-4315-8b8a-813662bf761e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_forecast(fc_name, all_features):\n",
    "    predictions = {}\n",
    "    for fc_time in FORECAST_TIMES:\n",
    "        model_id = f\"{fc_name}_Tp{fc_time}\"\n",
    "        \n",
    "        print(model_id + \" \", end=\"\")\n",
    "        \n",
    "        # get feature names for this particular model_id - by loading the fastai model and asking it!\n",
    "        temp_learner = load_fastai_nn_model(model_id)\n",
    "        data_for_this_model = {key: features[key] for key in temp_learner.dls.cont_names}\n",
    "        \n",
    "        # convenience: gather all used feature names, can be used to check\n",
    "        # global all_used_feature_names\n",
    "        # all_used_feature_names = all_used_feature_names | set(temp_learner.dls.cont_names)\n",
    "        \n",
    "        continue\n",
    "        predictions[f\"{model_id}_xgb\"] = predict_xgb(model_id, data_for_this_model)\n",
    "        predictions[f\"{model_id}_nn\"] = predict_fastai_nn(model_id, data_for_this_model)\n",
    "        predictions[f\"{model_id}_pred\"] = (predictions[f\"{model_id}_xgb\"] * (1-ENSEMBLE_RATIO) + \n",
    "                                           predictions[f\"{model_id}_nn\"] * ENSEMBLE_RATIO)\n",
    "    return predictions\n",
    "\n",
    "# log_features_and_predictions_to_db() takes the features pulled from aemo and the \n",
    "# results of the predictions and saves them to dynamodb for reference later. \n",
    "# features = {'VIC1_Price': 100, ...}\n",
    "# a forecast is a dict of predictions, forecasts is a dict of forecasts\n",
    "def log_features_and_predictions_to_db(base_time, features, forecasts):\n",
    "    # join each forecast together into a single dict\n",
    "    # predictions = {'VIC1_Price_Tp2_pred': 1000, ... 'VIC1_Greenness_Tp168_pred': 1000, ... 'NSW1_Price_Tp84_pred': 100, ...}\n",
    "    predictions = {}\n",
    "    for preds in forecasts.values():\n",
    "        predictions = predictions | preds\n",
    "        \n",
    "    # join input features and predictions\n",
    "    all_features = dict(sorted(list(features.items()) + list(predictions.items())))\n",
    "    \n",
    "    print(f\"TODO: write to database {len(all_features)} features, which includes {len(features)} features.\")\n",
    "    \n",
    "    # write all_features to database. \n",
    "    # key is current time we're forecasting from,\n",
    "    # value is all_features\n",
    "\n",
    "# interpolate_forecasts() puts predictions into a dataframe, adding an absolute time index on the way\n",
    "def interpolate_forecasts(forecasts, base_time): \n",
    "    # turn each forecast dict into a list, taking only the emsembled prediction ('..._pred') not \n",
    "    # the raw xgb/nn for each time.\n",
    "    preds_only = {}\n",
    "    for fc_name, fc in forecasts.items():\n",
    "        preds_only[fc_name] = [val for key, val in fc.items() if '_pred' in key]\n",
    "    df = pd.DataFrame(preds_only, index=FORECAST_TIMES)\n",
    "    \n",
    "    # change to datetime index\n",
    "    df.index = [base_time + pd.Timedelta(hours, 'H') for hours in df.index]\n",
    "    \n",
    "    # interpolate\n",
    "    df = df.resample('1H').interpolate(method='spline', order=3)\n",
    "\n",
    "    # format for output\n",
    "    output = {\n",
    "        'BaseTime': base_time.isoformat(),\n",
    "        'DateTime': pd.to_datetime(df.index).map(lambda x: x.isoformat()).to_list(),\n",
    "        'Forecasts': {col: df[col].values.round(2).tolist() for col in df.columns},\n",
    "    }\n",
    "    return output\n",
    "\n",
    "# deploy_forecasts() exports all the forecasts just made to S3\n",
    "# TODO: where to upload this stuff? where will it be cached??\n",
    "def deploy_forecasts(forecasts, filename):\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(forecasts, f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce4f93-1dae-4b35-9a89-7709c1e63d59",
   "metadata": {},
   "source": [
    "### Main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a91d84-4941-41c0-b630-f91790a23e1e",
   "metadata": {},
   "source": [
    "File format for forecasts: 'latest_forecasts.json':\n",
    "\n",
    "```\n",
    "{ \"BaseTime\": \"2022-09-26T15:00:00\",\n",
    "  \"DateTime\": [\"2022-09-26T17:00:00\", ..., \"2022-10-03T15:00:00\"],\n",
    "  \"Forecasts\": {\n",
    "    \"VIC1_Price\": [10.0, ... 11.0],\n",
    "    ...\n",
    "  }}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903bb81-a330-4d65-903d-af8fad503019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO... make sure this is the right time...\n",
    "base_time = pd.Timestamp.round(pd.Timestamp.now(), 'H')\n",
    "\n",
    "# collect all the current data \n",
    "features = get_test_features()\n",
    "\n",
    "# make forecasts\n",
    "forecasts = {}\n",
    "# for fc in FORECASTS_TO_MAKE:\n",
    "for fc in ['VIC1_Price', 'VIC1_Greenness']: #, 'TAS1_Price', 'TAS1_Greenness']:\n",
    "    forecasts[fc] = make_forecast(fc, features)\n",
    "\n",
    "interpolated = interpolate_forecasts(forecasts, base_time)\n",
    "\n",
    "deploy_forecasts(interpolated, 'latest_forecasts.json')\n",
    "\n",
    "\n",
    "with open('latest_forecasts.json') as f:\n",
    "    tmp = json.loads(f.read())\n",
    "print(json.dumps(tmp))\n",
    "\n",
    "# save raw data to db\n",
    "log_features_and_predictions_to_db(base_time, features, forecasts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780281a-ddb0-48b0-8f83-c5c2b2c5507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(interpolated['Forecasts'], index=interpolated['DateTime']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93906e5b-c817-476e-b33b-3c14552b7bd1",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a143d5b-b117-4c65-9fd4-5977c4eb7b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_files = [x for x in os.listdir() if '.json' in x]\n",
    "models = {x[:-5]: load_xgb_model(x) for x in model_files[:20]}\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9a97c-94db-46fb-abf3-02dd0f5da332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppjson(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e534e8-f234-45f0-935f-703083cfb880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(df.to_json(orient='columns', date_format='iso', date_unit='s')), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4d9a0-fb09-44fa-851f-fb99a2d0064a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert each forecast to just a single ordered list of values, all combined into one dict with the forecast name as key\n",
    "{ column: df[column].values.tolist() for column in df.columns}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f7740-c6f4-4b92-950e-b4284ba333aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75f9f0-4f43-41ea-a4b7-6fec4f13a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "{key: list(preds.values()) for key, preds in forecasts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f40ed-e6d0-421b-a07e-16eac3182972",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(models.values())[0].get_booster().feature_names\n",
    "len(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c7a49-25e8-4d6a-bb8f-91f587033fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = models['VIC1_Greenness_Tp13'].get_booster().feature_names\n",
    "vals = [1.0/len(x) for x in models['VIC1_Greenness_Tp13'].get_booster().feature_names]\n",
    "\n",
    "X = pd.DataFrame([vals], columns=column_names)\n",
    "# X = xgboost.DMatrix(np.array(vals).reshape(1,286), label=column_names)\n",
    "models['VIC1_Greenness_Tp13'].predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd53a2-03f0-430b-aa67-667c416cd46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072f6cd-aa45-44f7-b751-e05d82273b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2da37fe3-be35-4523-b123-d2d1086c5405",
   "metadata": {},
   "source": [
    "### Get list of y_names we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8c4ff-6507-4957-867f-cbff95d1441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = [f\"{region}_{"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8deeb13-4a4c-499f-8f96-7fa92fad01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_to_make = []\n",
    "for price_or_greenness in ['Price', 'Greenness']:\n",
    "    for region in REGIONIDS:\n",
    "        for model_type in ['fastai_nn', 'xgboost']:\n",
    "            for forecast in FORECAST_TIMES:\n",
    "                predictions_to_make.append(f'{region}_{price_or_greenness}_Tp{forecast}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mxy-py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "99a9edb481615ced1a0782653f07cf4c82d74e93bae55075c799593c81d8b216"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
